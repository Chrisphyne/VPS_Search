{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2baa8e2-5fc4-4272-b15e-35b2aea517ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: psycopg2-binary in ./.venv/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: langchain-google-genai in ./.venv/lib/python3.12/site-packages (2.1.9)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: chromadb in ./.venv/lib/python3.12/site-packages (1.0.15)\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.12/site-packages (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.4.11)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (0.6.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (0.2.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.14.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.21.4)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.12/site-packages (from chromadb) (3.11.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.25.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.31.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./.venv/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (0.34.3)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community langgraph psycopg2-binary langchain-google-genai pandas numpy chromadb langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa78569-d117-4827-af7a-4dcd7ddf9996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "\"\"\"\n",
    "Enhanced RAG System for JSONB Occurrence Data\n",
    "=============================================\n",
    "\n",
    "This system demonstrates how to make your JSONB occurrence data intelligently \n",
    "available to your LLM with field schema understanding.\n",
    "\n",
    "Key Features:\n",
    "- Dynamic field schema loading from sub_module table\n",
    "- Smart JSONB querying with field-aware SQL generation  \n",
    "- Vector search on occurrence content for semantic similarity\n",
    "- Field-aware LLM responses that understand your data structure\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain and AI imports\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f4476b-82b5-4dfc-afa0-432553007f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database connected successfully!\n",
      "Available tables: ['IPRS_Person', 'ModuleData', 'Modules', '_prisma_migrations', 'sub_module', 'sub_module_data']\n",
      "✅ LLM and embeddings initialized!\n",
      "✅ Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Environment Configuration\n",
    "\"\"\"\n",
    "Configure environment variables and initialize database/AI connections\n",
    "\"\"\"\n",
    "\n",
    "# Set up environment variables\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyDsJJu5oN0BQrEKvnotU6uYEl5Mxw9fiug'\n",
    "#os.environ['GOOGLE_API_KEY'] = 'AIzaSyBwM-8qWcUoYY5TjQZYunatHsF3RGspoJo'\n",
    "os.environ['LANGSMITH_API_KEY'] = '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'\n",
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "\n",
    "# Database connection settings\n",
    "os.environ['DB_HOST'] = 'localhost'\n",
    "os.environ['DB_PORT'] = '5432'\n",
    "os.environ['DB_NAME'] = 'obmain'\n",
    "os.environ['DB_USER'] = 'myuser'\n",
    "os.environ['DB_PASSWORD'] = 'Welcome123'\n",
    "\n",
    "# Initialize database connection\n",
    "db_uri = f\"postgresql://{os.environ['DB_USER']}:{os.environ['DB_PASSWORD']}@{os.environ['DB_HOST']}:{os.environ['DB_PORT']}/{os.environ['DB_NAME']}\"\n",
    "\n",
    "try:\n",
    "    db = SQLDatabase.from_uri(db_uri)\n",
    "    print(\"✅ Database connected successfully!\")\n",
    "    print(f\"Available tables: {db.get_usable_table_names()}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Database connection failed: {e}\")\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "print(\"✅ LLM and embeddings initialized!\")\n",
    "print(\"✅ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895e86de-7ce2-46c5-b2ff-838511c7fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded schemas for 16 modules\n",
      "✅ Field Schema Manager initialized!\n",
      "\n",
      "Available Occurrence Types and Sample Fields:\n",
      "============================================================\n",
      "\n",
      "1. Arson\n",
      "   Description: Vandalizing or damaging by burning down\n",
      "   Total fields: 8\n",
      "   Sample fields:\n",
      "     - Give a brief narrative of what happened (narrative)\n",
      "     - Type of property (select)\n",
      "     - Plot No (text)\n",
      "     ... and 5 more fields\n",
      "\n",
      "2. Assault\n",
      "   Description: Attack by a person on another\n",
      "   Total fields: 10\n",
      "   Sample fields:\n",
      "     - Who was assaulted (select)\n",
      "     - Name of the victim (text)\n",
      "     - Gender of the victim (select)\n",
      "     ... and 7 more fields\n",
      "\n",
      "3. Burglary\n",
      "   Description: Unlawful or forced entry into a building to commit a crime\n",
      "   Total fields: 31\n",
      "   Sample fields:\n",
      "     - select type of property broken into (single-choice)\n",
      "     - Property Name (tetx)\n",
      "     - LR Number (tetx)\n",
      "     ... and 28 more fields\n",
      "\n",
      "4. Cyber Crime\n",
      "   Description: Criminal activity that are carried out using digital devices and networks\n",
      "   Total fields: 8\n",
      "   Sample fields:\n",
      "     - Select Incident (select)\n",
      "     - Who is the victim (single-choice)\n",
      "     - Relationship (select)\n",
      "     ... and 5 more fields\n",
      "\n",
      "5. Death\n",
      "   Description: Death\n",
      "   Total fields: 11\n",
      "   Sample fields:\n",
      "     - Who is dead (select)\n",
      "     - Name (text)\n",
      "     - Age (select)\n",
      "     ... and 8 more fields\n",
      "\n",
      "6. Homicide\n",
      "   Description: Intentional murder manslaughter or killing of a person\n",
      "   Total fields: 9\n",
      "   Sample fields:\n",
      "     - Who is dead (select)\n",
      "     - Name of the deceased (text)\n",
      "     - Gender of deceased (select)\n",
      "     ... and 6 more fields\n",
      "\n",
      "8. Motor Vehicle Theft\n",
      "   Description: Motor Vehicle Theft\n",
      "   Total fields: 8\n",
      "   Sample fields:\n",
      "     - Body type (select)\n",
      "     - Registration number (text)\n",
      "     - Make (select)\n",
      "     ... and 5 more fields\n",
      "\n",
      "9. Rape\n",
      "   Description: Rape\n",
      "   Total fields: 14\n",
      "   Sample fields:\n",
      "     - Who was raped (single-choice)\n",
      "     - Name (text)\n",
      "     - Gender (select)\n",
      "     ... and 11 more fields\n",
      "\n",
      "7. Missing Person\n",
      "   Description: Missing Person\n",
      "   Total fields: 14\n",
      "   Sample fields:\n",
      "     - Who is missing (single-choice)\n",
      "     - Name (text)\n",
      "     - Gender (select)\n",
      "     ... and 11 more fields\n",
      "\n",
      "10. Robbery\n",
      "   Description: Robbery\n",
      "   Total fields: 26\n",
      "   Sample fields:\n",
      "     - What category of items were stolen (multi-select)\n",
      "     - type of electronic (multi-select)\n",
      "     - Television serial number (text)\n",
      "     ... and 23 more fields\n",
      "\n",
      "12. GBV\n",
      "   Description: gender based violence\n",
      "   Total fields: 23\n",
      "   Sample fields:\n",
      "     - Type of GBV (single-choice)\n",
      "     - Sexual Violence (select)\n",
      "     - Physical Violence (select)\n",
      "     ... and 20 more fields\n",
      "\n",
      "11. Stolen Lost Item\n",
      "   Description: Stolen Lost Item\n",
      "   Total fields: 22\n",
      "   Sample fields:\n",
      "     - What category of items were stolen (multi-select)\n",
      "     - type of electronic (multi-select)\n",
      "     - Television serial number (text)\n",
      "     ... and 19 more fields\n",
      "\n",
      "13. Visits\n",
      "   Description: \n",
      "   Total fields: 3\n",
      "   Sample fields:\n",
      "     - ID_Number (iprs)\n",
      "     - Profile (select)\n",
      "     - Reason For Visiting (narrative)\n",
      "\n",
      "14. Events\n",
      "   Description: \n",
      "   Total fields: 2\n",
      "   Sample fields:\n",
      "     - Event Name (text)\n",
      "     - Narrative (narrative)\n",
      "\n",
      "15. Incidents\n",
      "   Description: \n",
      "   Total fields: 4\n",
      "   Sample fields:\n",
      "     - Incident Type (select)\n",
      "     - Injuries (select)\n",
      "     - Number (text)\n",
      "     ... and 1 more fields\n",
      "\n",
      "16. Natural Disasters\n",
      "   Description: \n",
      "   Total fields: 4\n",
      "   Sample fields:\n",
      "     - Disaster Type (select)\n",
      "     - Injuries (select)\n",
      "     - Number (text)\n",
      "     ... and 1 more fields\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Field Schema Manager\n",
    "\"\"\"\n",
    "This class extracts and manages the field schemas from your sub_module table.\n",
    "It understands what fields are available for each occurrence type (Arson, Theft, Death, etc.).\n",
    "\"\"\"\n",
    "\n",
    "class FieldSchemaManager:\n",
    "    \"\"\"Manages field schemas from sub_module table\"\"\"\n",
    "    \n",
    "    def __init__(self, db: SQLDatabase):\n",
    "        self.db = db\n",
    "        self.schemas = {}\n",
    "        self.load_schemas()\n",
    "    \n",
    "    def load_schemas(self):\n",
    "        \"\"\"Load all field schemas from sub_module table\"\"\"\n",
    "        query = \"SELECT id, name, description, fields FROM sub_module\"\n",
    "        result = self.db.run(query)\n",
    "        \n",
    "        # Parse the result\n",
    "        import ast\n",
    "        rows = ast.literal_eval(result)\n",
    "        \n",
    "        for row in rows:\n",
    "            module_id, name, description, fields_json = row\n",
    "            if fields_json:\n",
    "                self.schemas[module_id] = {\n",
    "                    'name': name,\n",
    "                    'description': description,\n",
    "                    'fields': fields_json\n",
    "                }\n",
    "        \n",
    "        print(f\"Loaded schemas for {len(self.schemas)} modules\")\n",
    "    \n",
    "    def get_field_info(self, module_id: int) -> Dict:\n",
    "        \"\"\"Get field information for a specific module\"\"\"\n",
    "        return self.schemas.get(module_id, {})\n",
    "    \n",
    "    def get_all_field_names(self) -> List[str]:\n",
    "        \"\"\"Get all unique field names across all modules\"\"\"\n",
    "        all_fields = set()\n",
    "        for schema in self.schemas.values():\n",
    "            for field in schema.get('fields', []):\n",
    "                all_fields.add(field.get('name', ''))\n",
    "        return list(all_fields)\n",
    "    \n",
    "    def create_field_description(self, module_id: int) -> str:\n",
    "        \"\"\"Create human-readable field descriptions for LLM\"\"\"\n",
    "        schema = self.get_field_info(module_id)\n",
    "        if not schema:\n",
    "            return \"No schema information available\"\n",
    "        \n",
    "        description = f\"Module: {schema['name']} - {schema['description']}\\n\\nFields:\\n\"\n",
    "        \n",
    "        for field in schema.get('fields', []):\n",
    "            field_name = field.get('name', 'Unknown')\n",
    "            field_type = field.get('type', 'text')\n",
    "            required = field.get('required', False)\n",
    "            options = field.get('options', [])\n",
    "            \n",
    "            description += f\"- {field_name} ({field_type})\"\n",
    "            if required:\n",
    "                description += \" [REQUIRED]\"\n",
    "            if options:\n",
    "                description += f\" Options: {', '.join(options[:5])}{'...' if len(options) > 5 else ''}\"\n",
    "            description += \"\\n\"\n",
    "        \n",
    "        return description\n",
    "\n",
    "# Initialize the schema manager\n",
    "schema_manager = FieldSchemaManager(db)\n",
    "print(\"✅ Field Schema Manager initialized!\")\n",
    "\n",
    "# Display available modules and their schemas\n",
    "print(\"\\nAvailable Occurrence Types and Sample Fields:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for module_id, schema in schema_manager.schemas.items():\n",
    "    print(f\"\\n{module_id}. {schema['name']}\")\n",
    "    print(f\"   Description: {schema['description']}\")\n",
    "    print(f\"   Total fields: {len(schema['fields'])}\")\n",
    "    \n",
    "    # Show first few fields as example\n",
    "    print(\"   Sample fields:\")\n",
    "    for field in schema['fields'][:3]:\n",
    "        field_name = field.get('name', 'Unknown')\n",
    "        field_type = field.get('type', 'text')\n",
    "        print(f\"     - {field_name} ({field_type})\")\n",
    "    \n",
    "    if len(schema['fields']) > 3:\n",
    "        print(f\"     ... and {len(schema['fields']) - 3} more fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfdae557-89e6-497f-aea1-9a54dc974eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSONB Query Builder initialized!\n",
      "\n",
      "Testing Query Builder:\n",
      "========================================\n",
      "✅ Successfully retrieved recent occurrences\n",
      "Sample result (truncated): [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 8, 'Motor Vehicle Theft', 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color...\n",
      "\n",
      "Searching for 'stolen' in occurrences:\n",
      "✅ Found occurrences containing 'stolen'\n",
      "Sample result: [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color': 'Black', 'Model': 'XC90...\n",
      "\n",
      "Occurrence Statistics by Module:\n",
      "Statistics: [('Arson', 287, 8, 71), ('Stolen Lost Item', 48, 12, 0), ('Motor Vehicle Theft', 40, 8, 1), ('Death', 32, 6, 7), ('Cyber Crime', 32, 2, 0), ('Assault', 23, 2, 3), ('Robbery', 18, 12, 0), ('Rape', 14, 1, 1), ('Homicide', 7, 2, 1), ('Missing Person', 4, 1, 0), ('Visits', 2, 0, 0), ('GBV', 1, 0, 0)]...\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Smart JSONB Query Builder\n",
    "\"\"\"\n",
    "This class builds intelligent SQL queries that can extract and interpret \n",
    "data from your JSONB formData columns.\n",
    "\"\"\"\n",
    "\n",
    "class JSONBQueryBuilder:\n",
    "    \"\"\"Build intelligent SQL queries for JSONB data\"\"\"\n",
    "    \n",
    "    def __init__(self, db: SQLDatabase, schema_manager: FieldSchemaManager):\n",
    "        self.db = db\n",
    "        self.schema_manager = schema_manager\n",
    "    \n",
    "    def build_occurrence_query(self, limit: int = 10, module_id: Optional[int] = None) -> str:\n",
    "        \"\"\"Build query to get occurrence data with schema information\"\"\"\n",
    "        base_query = \"\"\"\n",
    "        SELECT \n",
    "            smd.id,\n",
    "            smd.ob_number,\n",
    "            smd.\"submissionDate\",\n",
    "            smd.\"sub_moduleId\",\n",
    "            sm.name as module_name,\n",
    "            sm.description as module_description,\n",
    "            smd.\"formData\",\n",
    "            smd.location,\n",
    "            smd.urgency,\n",
    "            smd.narrative,\n",
    "            ip.first_name,\n",
    "            ip.last_name,\n",
    "            ip.id_no\n",
    "        FROM sub_module_data smd\n",
    "        LEFT JOIN sub_module sm ON smd.\"sub_moduleId\" = sm.id\n",
    "        LEFT JOIN \"IPRS_Person\" ip ON smd.\"iprsId\" = ip.id\n",
    "        \"\"\"\n",
    "        \n",
    "        if module_id:\n",
    "            base_query += f\" WHERE smd.\\\"sub_moduleId\\\" = {module_id}\"\n",
    "        \n",
    "        base_query += f\" ORDER BY smd.\\\"submissionDate\\\" DESC LIMIT {limit}\"\n",
    "        \n",
    "        return base_query\n",
    "    \n",
    "    def search_in_jsonb(self, search_term: str, limit: int = 10) -> str:\n",
    "        \"\"\"Build query to search within JSONB formData\"\"\"\n",
    "        return f\"\"\"\n",
    "        SELECT \n",
    "            smd.id,\n",
    "            smd.ob_number,\n",
    "            smd.\"submissionDate\",\n",
    "            sm.name as module_name,\n",
    "            smd.\"formData\",\n",
    "            smd.location,\n",
    "            smd.urgency\n",
    "        FROM sub_module_data smd\n",
    "        LEFT JOIN sub_module sm ON smd.\"sub_moduleId\" = sm.id\n",
    "        WHERE smd.\"formData\"::text ILIKE '%{search_term}%'\n",
    "        OR smd.narrative ILIKE '%{search_term}%'\n",
    "        ORDER BY smd.\"submissionDate\" DESC\n",
    "        LIMIT {limit}\n",
    "        \"\"\"\n",
    "    \n",
    "    def get_statistics_by_module(self) -> str:\n",
    "        \"\"\"Get occurrence statistics by module type\"\"\"\n",
    "        return \"\"\"\n",
    "        SELECT \n",
    "            sm.name as module_name,\n",
    "            COUNT(*) as total_occurrences,\n",
    "            COUNT(CASE WHEN smd.\"submissionDate\" >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as last_30_days,\n",
    "            COUNT(CASE WHEN smd.urgency = 'High' THEN 1 END) as high_urgency\n",
    "        FROM sub_module_data smd\n",
    "        LEFT JOIN sub_module sm ON smd.\"sub_moduleId\" = sm.id\n",
    "        GROUP BY sm.id, sm.name\n",
    "        ORDER BY total_occurrences DESC\n",
    "        \"\"\"\n",
    "    \n",
    "    def execute_query(self, query: str) -> Any:\n",
    "        \"\"\"Execute query and return results\"\"\"\n",
    "        try:\n",
    "            return self.db.run(query)\n",
    "        except Exception as e:\n",
    "            print(f\"Query execution error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize query builder\n",
    "query_builder = JSONBQueryBuilder(db, schema_manager)\n",
    "print(\"✅ JSONB Query Builder initialized!\")\n",
    "\n",
    "# Test the query builder\n",
    "print(\"\\nTesting Query Builder:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get recent occurrences\n",
    "recent_query = query_builder.build_occurrence_query(limit=3)\n",
    "recent_results = query_builder.execute_query(recent_query)\n",
    "\n",
    "if recent_results:\n",
    "    print(\"✅ Successfully retrieved recent occurrences\")\n",
    "    print(f\"Sample result (truncated): {str(recent_results)[:200]}...\")\n",
    "else:\n",
    "    print(\"❌ No results returned\")\n",
    "\n",
    "# Search for specific terms\n",
    "print(\"\\nSearching for 'stolen' in occurrences:\")\n",
    "search_query = query_builder.search_in_jsonb(\"stolen\", limit=2)\n",
    "search_results = query_builder.execute_query(search_query)\n",
    "\n",
    "if search_results:\n",
    "    print(\"✅ Found occurrences containing 'stolen'\")\n",
    "    print(f\"Sample result: {str(search_results)[:200]}...\")\n",
    "else:\n",
    "    print(\"❌ No 'stolen' occurrences found\")\n",
    "\n",
    "# Get statistics\n",
    "print(\"\\nOccurrence Statistics by Module:\")\n",
    "stats_query = query_builder.get_statistics_by_module()\n",
    "stats_results = query_builder.execute_query(stats_query)\n",
    "if stats_results:\n",
    "    print(f\"Statistics: {str(stats_results)[:300]}...\")\n",
    "else:\n",
    "    print(\"❌ No statistics available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6339f7f4-cc2e-4e13-a9a2-038804ba299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Processor and Vector Store (FINAL FIX) initialized!\n",
      "\n",
      "Debug - Sample result type: <class 'str'>\n",
      "Debug - Sample result: [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 8, 'Motor Vehicle Theft', 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color': 'Black', 'Model': 'XC90', 'location': '22, Brookside Dr', 'Body type': 'SUV', 'Car description': ...\n",
      "\n",
      "✅ Successfully parsed 2 occurrences!\n",
      "Sample processed occurrence:\n",
      "==================================================\n",
      "OB Number: OB/69/1611/7/29/2025\n",
      "Date: 2025-07-29 08:10:11.123000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Reporter: Michel Cheboi\n",
      "ID Number: 36445676\n",
      "\n",
      "Occurrence Details:\n",
      "- Pin: Lat: -1.2561485, long: 36.7919722\n",
      "- Make: Volvo\n",
      "- Color: Black\n",
      "- Model: XC90\n",
      "- Location: 22, Brookside Dr\n",
      "- Body Type: SUV\n",
      "- Car Description: New\n",
      "- Registration Number: KGM 333M\n",
      "- Date And Time Of Occurrence: 2025-07-29 10:53\n",
      "- A Brief Narrative Of What Happened: stolen \n",
      "\n",
      "Narrative: \t 22, Brookside Dr\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Data Processor and Vector Store (FINAL FIX)\n",
    "\"\"\"\n",
    "Process occurrence data for LLM consumption and create vector store for semantic search\n",
    "FINAL FIX: Handle database results with datetime objects properly\n",
    "\"\"\"\n",
    "\n",
    "class OccurrenceDataProcessor:\n",
    "    \"\"\"Process occurrence data for LLM consumption\"\"\"\n",
    "    \n",
    "    def __init__(self, schema_manager: FieldSchemaManager):\n",
    "        self.schema_manager = schema_manager\n",
    "    \n",
    "    def format_occurrence_for_llm(self, occurrence_data: Dict) -> str:\n",
    "        \"\"\"Format occurrence data into human-readable text for LLM\"\"\"\n",
    "        formatted = []\n",
    "        \n",
    "        # Basic occurrence info\n",
    "        formatted.append(f\"OB Number: {occurrence_data.get('ob_number', 'N/A')}\")\n",
    "        formatted.append(f\"Date: {occurrence_data.get('submissionDate', 'N/A')}\")\n",
    "        formatted.append(f\"Type: {occurrence_data.get('module_name', 'N/A')}\")\n",
    "        formatted.append(f\"Description: {occurrence_data.get('module_description', 'N/A')}\")\n",
    "        \n",
    "        if occurrence_data.get('location'):\n",
    "            formatted.append(f\"Location: {occurrence_data['location']}\")\n",
    "        \n",
    "        if occurrence_data.get('urgency'):\n",
    "            formatted.append(f\"Urgency: {occurrence_data['urgency']}\")\n",
    "        \n",
    "        # Person information\n",
    "        if occurrence_data.get('first_name'):\n",
    "            name = f\"{occurrence_data.get('first_name', '')} {occurrence_data.get('last_name', '')}\".strip()\n",
    "            formatted.append(f\"Reporter: {name}\")\n",
    "        \n",
    "        if occurrence_data.get('id_no'):\n",
    "            formatted.append(f\"ID Number: {occurrence_data['id_no']}\")\n",
    "        \n",
    "        # Process JSONB form data\n",
    "        form_data = occurrence_data.get('formData', {})\n",
    "        if isinstance(form_data, str):\n",
    "            try:\n",
    "                form_data = json.loads(form_data)\n",
    "            except:\n",
    "                form_data = {}\n",
    "        \n",
    "        if form_data:\n",
    "            formatted.append(\"\\nOccurrence Details:\")\n",
    "            \n",
    "            for key, value in form_data.items():\n",
    "                if value and str(value).strip() and str(value) != 'null':\n",
    "                    # Clean up the key name\n",
    "                    clean_key = key.replace('_', ' ').title()\n",
    "                    formatted.append(f\"- {clean_key}: {value}\")\n",
    "        \n",
    "        if occurrence_data.get('narrative'):\n",
    "            formatted.append(f\"\\nNarrative: {occurrence_data['narrative']}\")\n",
    "        \n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def create_occurrence_documents(self, occurrences: List[Dict]) -> List[Document]:\n",
    "        \"\"\"Create LangChain documents from occurrence data\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for occurrence in occurrences:\n",
    "            content = self.format_occurrence_for_llm(occurrence)\n",
    "            \n",
    "            metadata = {\n",
    "                'ob_number': occurrence.get('ob_number', ''),\n",
    "                'module_name': occurrence.get('module_name', ''),\n",
    "                'submission_date': str(occurrence.get('submissionDate', '')),\n",
    "                'urgency': occurrence.get('urgency', ''),\n",
    "                'location': occurrence.get('location', '')\n",
    "            }\n",
    "            \n",
    "            documents.append(Document(\n",
    "                page_content=content,\n",
    "                metadata=metadata\n",
    "            ))\n",
    "        \n",
    "        return documents\n",
    "\n",
    "def parse_db_result_to_dict(db_result) -> List[Dict]:\n",
    "    \"\"\"Parse database result into list of dictionaries - FINAL VERSION\"\"\"\n",
    "    try:\n",
    "        # The LangChain SQLDatabase.run() method returns a string representation\n",
    "        # We need to use eval() in a safe way or parse it manually\n",
    "        \n",
    "        if isinstance(db_result, str):\n",
    "            # The string contains datetime objects which ast.literal_eval can't handle\n",
    "            # Let's use a different approach - execute the string with datetime imported\n",
    "            import datetime\n",
    "            \n",
    "            # Create a safe environment for eval\n",
    "            safe_dict = {\n",
    "                \"datetime\": datetime,\n",
    "                \"__builtins__\": {}\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                rows = eval(db_result, safe_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not eval result: {e}\")\n",
    "                # Fallback: try to extract data manually from string\n",
    "                return parse_string_manually(db_result)\n",
    "                \n",
    "        elif isinstance(db_result, (list, tuple)):\n",
    "            rows = db_result\n",
    "        else:\n",
    "            print(f\"Unexpected result type: {type(db_result)}\")\n",
    "            return []\n",
    "        \n",
    "        # Convert to list if it's a single tuple\n",
    "        if isinstance(rows, tuple) and len(rows) > 0 and not isinstance(rows[0], (tuple, list)):\n",
    "            rows = [rows]\n",
    "        \n",
    "        # Define column names based on our query\n",
    "        columns = ['id', 'ob_number', 'submissionDate', 'sub_moduleId', 'module_name', \n",
    "                  'module_description', 'formData', 'location', 'urgency', 'narrative',\n",
    "                  'first_name', 'last_name', 'id_no']\n",
    "        \n",
    "        result = []\n",
    "        for row in rows:\n",
    "            if len(row) >= len(columns):\n",
    "                occurrence_dict = dict(zip(columns, row))\n",
    "                result.append(occurrence_dict)\n",
    "            else:\n",
    "                print(f\"Row has {len(row)} columns, expected {len(columns)}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing result: {e}\")\n",
    "        print(f\"Result type: {type(db_result)}\")\n",
    "        return []\n",
    "\n",
    "def parse_string_manually(db_result_string: str) -> List[Dict]:\n",
    "    \"\"\"Fallback manual parsing if eval fails\"\"\"\n",
    "    try:\n",
    "        # This is a simple fallback - in practice, you might want more robust parsing\n",
    "        print(\"Attempting manual string parsing...\")\n",
    "        \n",
    "        # For now, let's try a simple approach\n",
    "        # Extract the tuples from the string manually\n",
    "        import re\n",
    "        \n",
    "        # Find all tuples in the string\n",
    "        tuple_pattern = r'\\(([^)]+)\\)'\n",
    "        matches = re.findall(tuple_pattern, db_result_string)\n",
    "        \n",
    "        print(f\"Found {len(matches)} potential matches\")\n",
    "        return []  # Return empty for now, but at least we won't crash\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Manual parsing failed: {e}\")\n",
    "        return []\n",
    "\n",
    "class OccurrenceVectorStore:\n",
    "    \"\"\"Manage vector store for occurrence data\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings, data_processor: OccurrenceDataProcessor, query_builder: JSONBQueryBuilder):\n",
    "        self.embeddings = embeddings\n",
    "        self.data_processor = data_processor\n",
    "        self.query_builder = query_builder\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_occurrences_to_vectorstore(self, limit: int = 50):\n",
    "        \"\"\"Load occurrences into vector store\"\"\"\n",
    "        print(f\"Loading {limit} recent occurrences into vector store...\")\n",
    "        \n",
    "        # Get occurrence data\n",
    "        query = self.query_builder.build_occurrence_query(limit=limit)\n",
    "        results = self.query_builder.execute_query(query)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No occurrence data found\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Raw result type: {type(results)}\")\n",
    "        print(f\"Raw result sample: {str(results)[:200]}...\")\n",
    "        \n",
    "        # Parse results\n",
    "        occurrences = parse_db_result_to_dict(results)\n",
    "        print(f\"Parsed {len(occurrences)} occurrences\")\n",
    "        \n",
    "        if not occurrences:\n",
    "            print(\"❌ No occurrences parsed successfully\")\n",
    "            return\n",
    "        \n",
    "        # Create documents\n",
    "        documents = self.data_processor.create_occurrence_documents(occurrences)\n",
    "        print(f\"Created {len(documents)} documents\")\n",
    "        \n",
    "        # Split documents if they're too long\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        \n",
    "        split_docs = text_splitter.split_documents(documents)\n",
    "        print(f\"Split into {len(split_docs)} chunks\")\n",
    "        \n",
    "        # Create vector store\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=split_docs,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=\"./occurrence_vectorstore\"\n",
    "        )\n",
    "        \n",
    "        # Create retriever\n",
    "        self.retriever = self.vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 5}\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Vector store created successfully!\")\n",
    "    \n",
    "    def search_similar_occurrences(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"Search for similar occurrences\"\"\"\n",
    "        if not self.retriever:\n",
    "            print(\"Vector store not initialized. Call load_occurrences_to_vectorstore first.\")\n",
    "            return []\n",
    "        \n",
    "        return self.retriever.invoke(query)\n",
    "\n",
    "# Re-initialize data processor and vector store\n",
    "data_processor = OccurrenceDataProcessor(schema_manager)\n",
    "vector_store = OccurrenceVectorStore(embeddings, data_processor, query_builder)\n",
    "\n",
    "print(\"✅ Data Processor and Vector Store (FINAL FIX) initialized!\")\n",
    "\n",
    "# Test data processing with sample occurrences\n",
    "sample_query = query_builder.build_occurrence_query(limit=2)\n",
    "sample_results = query_builder.execute_query(sample_query)\n",
    "\n",
    "print(f\"\\nDebug - Sample result type: {type(sample_results)}\")\n",
    "print(f\"Debug - Sample result: {str(sample_results)[:300]}...\")\n",
    "\n",
    "if sample_results:\n",
    "    sample_occurrences = parse_db_result_to_dict(sample_results)\n",
    "    \n",
    "    if sample_occurrences:\n",
    "        print(f\"\\n✅ Successfully parsed {len(sample_occurrences)} occurrences!\")\n",
    "        print(\"Sample processed occurrence:\")\n",
    "        print(\"=\" * 50)\n",
    "        formatted_sample = data_processor.format_occurrence_for_llm(sample_occurrences[0])\n",
    "        print(formatted_sample[:500] + \"...\" if len(formatted_sample) > 500 else formatted_sample)\n",
    "    else:\n",
    "        print(\"❌ No sample data to process\")\n",
    "else:\n",
    "    print(\"❌ No sample data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e15dd01-d16e-4940-a956-41d0a3c97f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading occurrences into vector store...\n",
      "Loading 100 recent occurrences into vector store...\n",
      "Raw result type: <class 'str'>\n",
      "Raw result sample: [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 8, 'Motor Vehicle Theft', 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color...\n",
      "Parsed 100 occurrences\n",
      "Created 100 documents\n",
      "Split into 102 chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store created successfully!\n",
      "\n",
      "Testing Semantic Search:\n",
      "==================================================\n",
      "\n",
      "Searching for: 'vehicle theft at sarit center'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1598/7/29/2025\n",
      "Type: Motor Vehicle Theft\n",
      "Content: OB Number: OB/69/1598/7/29/2025\n",
      "Date: 2025-07-28 22:43:38.570000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Reporter: David Mutavi\n",
      "ID ...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/69/1598/7/29/2025\n",
      "Type: Motor Vehicle Theft\n",
      "Content: OB Number: OB/69/1598/7/29/2025\n",
      "Date: 2025-07-28 22:43:38.570000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Reporter: David Mutavi\n",
      "ID ...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/69/1598/7/29/2025\n",
      "Type: Motor Vehicle Theft\n",
      "Content: OB Number: OB/69/1598/7/29/2025\n",
      "Date: 2025-07-28 22:43:38.570000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Reporter: David Mutavi\n",
      "ID ...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/69/1602/7/29/2025\n",
      "Type: Robbery\n",
      "Content: OB Number: OB/69/1602/7/29/2025\n",
      "Date: 2025-07-29 06:18:00.703000\n",
      "Type: Robbery\n",
      "Description: Robbery\n",
      "Reporter: Michael Kamau\n",
      "ID Number: 21393375\n",
      "\n",
      "Occur...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/69/1602/7/29/2025\n",
      "Type: Robbery\n",
      "Content: OB Number: OB/69/1602/7/29/2025\n",
      "Date: 2025-07-29 06:18:00.703000\n",
      "Type: Robbery\n",
      "Description: Robbery\n",
      "Reporter: Michael Kamau\n",
      "ID Number: 21393375\n",
      "\n",
      "Occur...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'death due to accident'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/012/1558/7/17/2025\n",
      "Type: Death\n",
      "Content: OB Number: OB/012/1558/7/17/2025\n",
      "Date: 2025-07-17 10:58:58.171000\n",
      "Type: Death\n",
      "Description: Death\n",
      "Urgency: High\n",
      "Reporter: Michel Cheboi\n",
      "ID Number: 3644...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/012/1558/7/17/2025\n",
      "Type: Death\n",
      "Content: OB Number: OB/012/1558/7/17/2025\n",
      "Date: 2025-07-17 10:58:58.171000\n",
      "Type: Death\n",
      "Description: Death\n",
      "Urgency: High\n",
      "Reporter: Michel Cheboi\n",
      "ID Number: 3644...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: Occurrence Details:\n",
      "- Pin: Lat: -1.2526035, long: 36.782478\n",
      "- Plot No: 456793P\n",
      "- Location: 47, Shanzu Rd\n",
      "- Type Of Property: Residential\n",
      "- Are You The...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'stolen laptop'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1610/7/29/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/69/1610/7/29/2025\n",
      "Date: 2025-07-29 08:01:56.170000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Michel Cheboi\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/69/1610/7/29/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/69/1610/7/29/2025\n",
      "Date: 2025-07-29 08:01:56.170000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Michel Cheboi\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/69/1610/7/29/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/69/1610/7/29/2025\n",
      "Date: 2025-07-29 08:01:56.170000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Michel Cheboi\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/1/1578/7/28/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1578/7/28/2025\n",
      "Date: 2025-07-27 22:19:37.064000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/1/1578/7/28/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1578/7/28/2025\n",
      "Date: 2025-07-27 22:19:37.064000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'fire incidents'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/177/1555/7/3/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/177/1555/7/3/2025\n",
      "Date: 2025-07-03 11:12:36.338000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Urgency: High\n",
      "Report...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/177/1555/7/3/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/177/1555/7/3/2025\n",
      "Date: 2025-07-03 11:12:36.338000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Urgency: High\n",
      "Report...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: Occurrence Details:\n",
      "- Pin: Lat: -1.2526035, long: 36.782478\n",
      "- Plot No: 456793P\n",
      "- Location: 47, Shanzu Rd\n",
      "- Type Of Property: Residential\n",
      "- Are You The...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'missing person child'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/1/1578/7/28/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1578/7/28/2025\n",
      "Date: 2025-07-27 22:19:37.064000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/1/1578/7/28/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1578/7/28/2025\n",
      "Date: 2025-07-27 22:19:37.064000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/233/1592/7/28/2025\n",
      "Type: Missing Person\n",
      "Content: OB Number: OB/233/1592/7/28/2025\n",
      "Date: 2025-07-28 13:33:51.910000\n",
      "Type: Missing Person\n",
      "Description: Missing Person\n",
      "Urgency: Medium\n",
      "Reporter: Mutuku Ky...\n",
      "-------------------------\n",
      "\n",
      "✅ Vector store loaded and semantic search tested!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load Vector Store and Test Semantic Search\n",
    "\"\"\"\n",
    "Load occurrence data into vector store and test semantic search capabilities\n",
    "\"\"\"\n",
    "\n",
    "# Load occurrences into vector store (this may take a few moments)\n",
    "print(\"Loading occurrences into vector store...\")\n",
    "vector_store.load_occurrences_to_vectorstore(limit=100)  # Start with 30 for testing\n",
    "\n",
    "# Test semantic search capabilities\n",
    "test_queries = [\n",
    "    \"vehicle theft at sarit center\",\n",
    "    \"death due to accident\", \n",
    "    \"stolen laptop\",\n",
    "    \"fire incidents\",\n",
    "    \"missing person child\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting Semantic Search:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nSearching for: '{query}'\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    results = vector_store.search_similar_occurrences(query, k=2)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i}:\")\n",
    "        print(f\"OB Number: {doc.metadata.get('ob_number', 'N/A')}\")\n",
    "        print(f\"Type: {doc.metadata.get('module_name', 'N/A')}\")\n",
    "        print(f\"Content: {doc.page_content[:150]}...\")\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "print(\"\\n✅ Vector store loaded and semantic search tested!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360f0f1e-f598-4e06-a30d-b8c39d815c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enhanced Occurrence RAG System initialized!\n",
      "\n",
      "Testing Enhanced RAG System\n",
      "============================================================\n",
      "\n",
      "1. Question: What types of vehicle theft have been reported recently?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided occurrence data, the only type of vehicle theft reported recently is **Motor Vehicle Theft**.\n",
      "\n",
      "These reports are associated with the following OB numbers:\n",
      "*   OB/69/1611/7/29/2025\n",
      "*   OB/69/1534/6/24/2025\n",
      "\n",
      "For occurrences of type \"Motor Vehicle Theft\", the following fields are ...\n",
      "\n",
      "============================================================\n",
      "\n",
      "2. Question: Tell me about arson cases and what property types are affected\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, here's information about arson cases and the property types affected:\n",
      "\n",
      "**Arson Cases and Affected Property Types:**\n",
      "\n",
      "From the available data, all detailed arson occurrences involve **Residential** properties.\n",
      "\n",
      "*   **OB Number: OB/177/1555/7/3/2025**\n",
      "    *   Typ...\n",
      "\n",
      "============================================================\n",
      "\n",
      "3. Question: What fields are available when reporting a missing person?\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, when reporting a **Missing Person** (as seen in OB Number: OB/233/1592/7/28/2025), the following fields are available:\n",
      "\n",
      "*   **Age**\n",
      "*   **Pin** (Latitude and Longitude)\n",
      "*   **Name**\n",
      "*   **Gender**\n",
      "*   **Location**\n",
      "*   **Height(Feet)**\n",
      "*   **Weight (Kgs)**\n",
      "*   *...\n",
      "\n",
      "============================================================\n",
      "\n",
      "4. Question: How many death cases have been reported?\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, there have been **0 (zero)** death cases reported.\n",
      "\n",
      "The occurrence types present in the provided OB numbers are:\n",
      "*   **Arson**: OB/69/1575/7/18/2025\n",
      "*   **Visits**: OB/069/1532/6/24/2025\n",
      "\n",
      "**Available Fields for Occurrence Types:**\n",
      "\n",
      "From the provided schema and ...\n",
      "\n",
      "============================================================\n",
      "\n",
      "5. Question: What are the common locations for theft incidents?\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, the common location for theft incidents (Stolen Lost Item) is **MWXC+MJ**.\n",
      "\n",
      "This location is associated with the following occurrences:\n",
      "*   **OB/1/1578/7/28/2025**\n",
      "*   **OB/1/1577/7/27/2025**\n",
      "\n",
      "The occurrence **OB/69/1610/7/29/2025** is also a 'Stolen Lost Item'...\n",
      "\n",
      "============================================================\n",
      "\n",
      "6. Question: How many reporters made occurrence reports this week? List them for me\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, \"this week\" refers to the week containing the most recent report date, which is July 18, 2025. This week spans from Monday, July 14, 2025, to Sunday, July 20, 2025.\n",
      "\n",
      "During this week, **1 reporter** made an occurrence report:\n",
      "*   **Faith Amusibwa** (for OB/69/1...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Enhanced RAG System\n",
    "\"\"\"\n",
    "Create the complete RAG system that understands field schemas and provides intelligent answers\n",
    "\"\"\"\n",
    "\n",
    "class EnhancedOccurrenceRAG:\n",
    "    \"\"\"Enhanced RAG system for occurrence data with schema awareness\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, vector_store: OccurrenceVectorStore, schema_manager: FieldSchemaManager, query_builder: JSONBQueryBuilder):\n",
    "        self.llm = llm\n",
    "        self.vector_store = vector_store\n",
    "        self.schema_manager = schema_manager\n",
    "        self.query_builder = query_builder\n",
    "        self.setup_prompts()\n",
    "    \n",
    "    def setup_prompts(self):\n",
    "        \"\"\"Setup prompts for different types of queries\"\"\"\n",
    "        \n",
    "        # General RAG prompt with schema awareness\n",
    "        self.rag_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent assistant analyzing police occurrence reports. You have access to:\n",
    "1. Occurrence data with structured fields\n",
    "2. Field schemas that define what information is available\n",
    "3. Historical occurrence patterns\n",
    "\n",
    "Available Occurrence Types and Their Fields:\n",
    "{schema_info}\n",
    "\n",
    "Context from similar occurrences:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Instructions:\n",
    "- Provide accurate information based on the occurrence data\n",
    "- Mention specific OB numbers when referencing occurrences\n",
    "- Explain what fields are available for different occurrence types\n",
    "- If asked about trends, analyze patterns in the data\n",
    "- If information is not available, clearly state this\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "    \n",
    "    def get_schema_summary(self) -> str:\n",
    "        \"\"\"Get summary of all available schemas\"\"\"\n",
    "        summary = []\n",
    "        for module_id, schema in self.schema_manager.schemas.items():\n",
    "            summary.append(f\"{schema['name']}: {schema['description']}\")\n",
    "        return \"\\n\".join(summary)\n",
    "    \n",
    "    def answer_question(self, question: str) -> str:\n",
    "        \"\"\"Answer question using RAG approach\"\"\"\n",
    "        # Get relevant documents\n",
    "        relevant_docs = self.vector_store.search_similar_occurrences(question)\n",
    "        \n",
    "        # Format context\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "        \n",
    "        # Get schema info\n",
    "        schema_info = self.get_schema_summary()\n",
    "        \n",
    "        # Generate answer\n",
    "        prompt = self.rag_prompt.format(\n",
    "            schema_info=schema_info,\n",
    "            context=context,\n",
    "            question=question\n",
    "        )\n",
    "        \n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response.content\n",
    "\n",
    "# Initialize enhanced RAG system\n",
    "enhanced_rag = EnhancedOccurrenceRAG(llm, vector_store, schema_manager, query_builder)\n",
    "print(\"✅ Enhanced Occurrence RAG System initialized!\")\n",
    "\n",
    "# Test the Enhanced RAG System\n",
    "test_questions = [\n",
    "    \"What types of vehicle theft have been reported recently?\",\n",
    "    \"Tell me about arson cases and what property types are affected\",\n",
    "    \"What fields are available when reporting a missing person?\",\n",
    "    \"How many death cases have been reported?\",\n",
    "    \"What are the common locations for theft incidents?\",\n",
    "    \"How many reporters made occurrence reports this week? List them for me\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting Enhanced RAG System\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        answer = enhanced_rag.answer_question(question)\n",
    "        print(f\"Answer: {answer[:300]}{'...' if len(answer) > 300 else ''}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54b3090-2099-4c48-b4a3-dbc889585774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Field Schema Understanding:\n",
      "==================================================\n",
      "\n",
      "Q: What information is collected for Motor Vehicle Theft cases?\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: For Motor Vehicle Theft cases, the following information is collected in the \"Occurrence Details\" based on the provided examples:\n",
      "\n",
      "**Commonly Collected Fields:**\n",
      "*   **Pin:** Geographic coordinates (Latitude and Longitude) of the occurrence.\n",
      "    *   ...\n",
      "\n",
      "Q: What fields are required when reporting an Arson incident?\n",
      "------------------------------\n",
      "A: Based on the provided occurrence data for Arson incidents, the following fields are consistently present in the \"Occurrence Details\" section, indicating they are required when reporting an Arson incident:\n",
      "\n",
      "*   **Pin:** This includes both Latitude (La...\n",
      "\n",
      "Q: Show me the available options for Cyber Crime incidents\n",
      "------------------------------\n",
      "A: Based on the provided occurrence data, the only available option for \"Select Incident\" under the \"Cyber Crime\" type is:\n",
      "\n",
      "*   **Computer fraud and forgery**\n",
      "\n",
      "This option is consistently present in all the listed Cyber Crime occurrences (e.g., OB/69/15...\n",
      "\n",
      "\n",
      "Example Queries:\n",
      "==============================\n",
      "\n",
      "Q: What vehicle thefts happened recently?\n",
      "A: Based on the provided occurrence data, here are the recent vehicle thefts:\n",
      "\n",
      "**Recent Vehicle Thefts:**\n",
      "\n",
      "1.  **OB Number: OB/69/1611/7/29/2025**\n",
      "    *   **Date of Occurrence:** 2025-07-29 10:53\n",
      "    *  ...\n",
      "\n",
      "Q: Show me death cases from accidents\n",
      "A: Based on the provided occurrence data, here is the death case reported as an accident:\n",
      "\n",
      "**Death Cases from Accidents:**\n",
      "\n",
      "*   **OB Number:** OB/012/1558/7/17/2025\n",
      "    *   **Date:** 2025-07-17 10:58:58....\n",
      "\n",
      "\n",
      "Direct Schema Exploration:\n",
      "========================================\n",
      "Motor Vehicle Theft Fields:\n",
      "Module: Motor Vehicle Theft - Motor Vehicle Theft\n",
      "\n",
      "Fields:\n",
      "- Body type (select) [REQUIRED] Options: Saloon, Sedan, Sports car, SUV, Minivan...\n",
      "- Registration number (text) [REQUIRED]\n",
      "- Make (select) [REQUIRED] Options: Ford, Honda, Toyota, Volvo, Mazda...\n",
      "- Model (text) [REQUIRED]\n",
      "- Color (text) [REQUIRED]\n",
      "- Car description (text)\n",
      "- Date and time of occurrence (datetime) [REQUIRED]\n",
      "- A brief narrative of what happened (narrative)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "🎉 ENHANCED RAG SYSTEM FOR JSONB OCCURRENCE DATA IS READY!\n",
      "================================================================================\n",
      "\n",
      "✅ What We've Built:\n",
      "\n",
      "1. **Field Schema Manager** - Automatically extracts and understands your dynamic field schemas\n",
      "2. **Smart JSONB Query Builder** - Creates intelligent SQL queries for JSONB data\n",
      "3. **Data Processor** - Formats occurrence data for LLM consumption\n",
      "4. **Vector Store** - Enables semantic search on occurrence content\n",
      "5. **Enhanced RAG System** - Provides intelligent, schema-aware responses\n",
      "\n",
      "🚀 Usage Examples:\n",
      "\n",
      "# Query for specific incidents\n",
      "query_occurrences(\"What vehicle thefts happened at Sarit Center?\")\n",
      "\n",
      "# Ask about field schemas  \n",
      "query_occurrences(\"What information is required for reporting arson?\")\n",
      "\n",
      "# Search for patterns\n",
      "query_occurrences(\"Show me all death cases caused by accidents\")\n",
      "\n",
      "# Get field information directly\n",
      "get_field_info(\"Missing Person\")\n",
      "\n",
      "📈 Performance Optimizations:\n",
      "\n",
      "For production use, consider:\n",
      "- Creating GIN indexes on JSONB columns: CREATE INDEX idx_formdata_gin ON sub_module_data USING GIN (\"formData\");\n",
      "- Implementing caching for frequent queries\n",
      "- Using connection pooling for database connections\n",
      "- Batch processing for large vector store updates\n",
      "\n",
      "Your JSONB occurrence data is now intelligently available to your LLM! 🎉\n",
      "\n",
      "\n",
      "Functions ready for use:\n",
      "- query_occurrences(question)\n",
      "- get_field_info(module_name)\n",
      "- enhanced_rag.answer_question(question)\n",
      "- vector_store.search_similar_occurrences(query)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Final Interface and Usage Examples\n",
    "\"\"\"\n",
    "Create a simple interface for querying your occurrence data and demonstrate usage\n",
    "\"\"\"\n",
    "\n",
    "def query_occurrences(question: str):\n",
    "    \"\"\"\n",
    "    Simple function to query your occurrence data\n",
    "    \n",
    "    Examples:\n",
    "    - query_occurrences(\"What vehicle thefts happened at Sarit Center?\")\n",
    "    - query_occurrences(\"Show me recent fire incidents\")\n",
    "    - query_occurrences(\"What fields are available for death reports?\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        answer = enhanced_rag.answer_question(question)\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f\"Error processing question: {e}\"\n",
    "\n",
    "def get_field_info(module_name: str):\n",
    "    \"\"\"\n",
    "    Get detailed field information for a specific occurrence type\n",
    "    \n",
    "    Examples:\n",
    "    - get_field_info(\"Motor Vehicle Theft\")\n",
    "    - get_field_info(\"Arson\")\n",
    "    - get_field_info(\"Missing Person\")\n",
    "    \"\"\"\n",
    "    for module_id, schema in schema_manager.schemas.items():\n",
    "        if schema['name'].lower() == module_name.lower():\n",
    "            return schema_manager.create_field_description(module_id)\n",
    "    \n",
    "    return f\"Module '{module_name}' not found. Available modules: {', '.join([s['name'] for s in schema_manager.schemas.values()])}\"\n",
    "\n",
    "# Test field-specific schema queries\n",
    "schema_questions = [\n",
    "    \"What information is collected for Motor Vehicle Theft cases?\",\n",
    "    \"What fields are required when reporting an Arson incident?\", \n",
    "    \"Show me the available options for Cyber Crime incidents\"\n",
    "]\n",
    "\n",
    "print(\"Testing Field Schema Understanding:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for question in schema_questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(\"-\" * 30)\n",
    "    answer = query_occurrences(question)\n",
    "    print(f\"A: {answer[:250]}{'...' if len(answer) > 250 else ''}\")\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n\\nExample Queries:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "example_questions = [\n",
    "    \"What vehicle thefts happened recently?\",\n",
    "    \"Show me death cases from accidents\"\n",
    "]\n",
    "\n",
    "for q in example_questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {query_occurrences(q)[:200]}...\")\n",
    "\n",
    "# Direct schema exploration\n",
    "print(\"\\n\\nDirect Schema Exploration:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Show detailed schema for Motor Vehicle Theft (ID 8)\n",
    "motor_vehicle_schema = get_field_info(\"Motor Vehicle Theft\")\n",
    "print(\"Motor Vehicle Theft Fields:\")\n",
    "print(motor_vehicle_schema[:500] + \"...\" if len(motor_vehicle_schema) > 500 else motor_vehicle_schema)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 ENHANCED RAG SYSTEM FOR JSONB OCCURRENCE DATA IS READY!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "✅ What We've Built:\n",
    "\n",
    "1. **Field Schema Manager** - Automatically extracts and understands your dynamic field schemas\n",
    "2. **Smart JSONB Query Builder** - Creates intelligent SQL queries for JSONB data\n",
    "3. **Data Processor** - Formats occurrence data for LLM consumption\n",
    "4. **Vector Store** - Enables semantic search on occurrence content\n",
    "5. **Enhanced RAG System** - Provides intelligent, schema-aware responses\n",
    "\n",
    "🚀 Usage Examples:\n",
    "\n",
    "# Query for specific incidents\n",
    "query_occurrences(\"What vehicle thefts happened at Sarit Center?\")\n",
    "\n",
    "# Ask about field schemas  \n",
    "query_occurrences(\"What information is required for reporting arson?\")\n",
    "\n",
    "# Search for patterns\n",
    "query_occurrences(\"Show me all death cases caused by accidents\")\n",
    "\n",
    "# Get field information directly\n",
    "get_field_info(\"Missing Person\")\n",
    "\n",
    "📈 Performance Optimizations:\n",
    "\n",
    "For production use, consider:\n",
    "- Creating GIN indexes on JSONB columns: CREATE INDEX idx_formdata_gin ON sub_module_data USING GIN (\"formData\");\n",
    "- Implementing caching for frequent queries\n",
    "- Using connection pooling for database connections\n",
    "- Batch processing for large vector store updates\n",
    "\n",
    "Your JSONB occurrence data is now intelligently available to your LLM! 🎉\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nFunctions ready for use:\")\n",
    "print(\"- query_occurrences(question)\")\n",
    "print(\"- get_field_info(module_name)\")\n",
    "print(\"- enhanced_rag.answer_question(question)\")\n",
    "print(\"- vector_store.search_similar_occurrences(query)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e59748-374d-47e2-aab8-57b9052b707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hybrid Search System initialized!\n",
      "\n",
      "🧪 Testing Hybrid Search System:\n",
      "============================================================\n",
      "\n",
      "1. Testing: How many vehicle thefts were reported in the last month?\n",
      "──────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Classified as: SQL\n",
      "💡 Reasoning: The question asks for a specific count (\"How many\") of a defined event type (\"vehicle thefts\") within a precise time frame (\"in the last month\"). All these elements (counts, filtering by specific criteria, and date ranges) are explicitly listed as capabilities of the SQL approach. It does not require semantic understanding or similarity search.\n",
      "\n",
      "Question: How many vehicle thefts were reported in the last month?\n",
      "============================================================\n",
      "🤖 Analysis: Using SQL approach\n",
      "💭 Reasoning: The question asks for a specific count (\"How many\") of a defined event type (\"vehicle thefts\") within a precise time frame (\"in the last month\"). All these elements (counts, filtering by specific criteria, and date ranges) are explicitly listed as capabilities of the SQL approach. It does not require semantic understanding or similarity search.\n",
      "------------------------------------------------------------\n",
      "🔍 Executing SQL search...\n",
      "Generated SQL: SELECT\n",
      "    COUNT(smd.id) AS total_vehicle_thefts_last_month\n",
      "FROM\n",
      "    sub_module_data smd\n",
      "JOIN\n",
      "    su...\n",
      "Query execution error: (psycopg2.errors.UndefinedColumn) column smd.sub_moduleid does not exist\n",
      "LINE 6:     sub_module sm ON smd.sub_moduleId = sm.id\n",
      "                             ^\n",
      "HINT:  Perhaps you meant to reference the column \"smd.sub_moduleId\".\n",
      "\n",
      "[SQL: SELECT\n",
      "    COUNT(smd.id) AS total_vehicle_thefts_last_month\n",
      "FROM\n",
      "    sub_module_data smd\n",
      "JOIN\n",
      "    sub_module sm ON smd.sub_moduleId = sm.id\n",
      "WHERE\n",
      "    sm.name ILIKE '%%vehicle theft%%' -- Filters for occurrence types related to vehicle theft\n",
      "    AND smd.submissionDate >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') -- Starts from the beginning of the previous calendar month\n",
      "    AND smd.submissionDate < DATE_TRUNC('month', CURRENT_DATE); -- Ends before the beginning of the current calendar month]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "No SQL results found\n",
      "\n",
      "============================================================\n",
      "\n",
      "2. Testing: Show me cases similar to stolen electronics at universities\n",
      "──────────────────────────────────────────────────\n",
      "🎯 Classified as: VECTOR\n",
      "💡 Reasoning: The core of the question is \"Show me cases similar to...\", which explicitly requires finding semantically related content. This is the primary function of a vector search, which uses embeddings to identify conceptual similarity rather than exact keyword matches or structured data filtering. The phrase \"stolen electronics at universities\" serves as the semantic query for the similarity search.\n",
      "\n",
      "Question: Show me cases similar to stolen electronics at universities\n",
      "============================================================\n",
      "🤖 Analysis: Using VECTOR approach\n",
      "💭 Reasoning: The core of the question is \"Show me cases similar to...\", which explicitly requires finding semantically related content. This is the primary function of a vector search, which uses embeddings to identify conceptual similarity rather than exact keyword matches or structured data filtering. The phrase \"stolen electronics at universities\" serves as the semantic query for the similarity search.\n",
      "------------------------------------------------------------\n",
      "🎯 Executing vector search...\n",
      "Match 1:\n",
      "OB: OB/69/1610/7/29/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/69/1610/7/29/2025\n",
      "Date: 2025-07-29 08:01:56.170000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Michel Cheboi\n",
      "ID Number: 36445676\n",
      "\n",
      "Occurrence Details:\n",
      "- Type Of Electro...\n",
      "------------------------------...\n",
      "\n",
      "============================================================\n",
      "\n",
      "3. Testing: What are the trends in cyber crime and give me some examples\n",
      "──────────────────────────────────────────────────\n",
      "🎯 Classified as: HYBRID\n",
      "💡 Reasoning: The question asks for \"trends,\" which requires aggregation and filtering by date and crime type (e.g., counting cyber crime incidents over time), a task best suited for SQL. It also asks for \"examples,\" which implies retrieving specific case details or narratives. To find relevant examples of \"cyber crime,\" especially if the definition is nuanced or described in narrative fields, a semantic search (VECTOR) would be highly effective. Combining the need for structured aggregation (SQL) and semantic content retrieval (VECTOR) makes HYBRID the optimal approach.\n",
      "\n",
      "Question: What are the trends in cyber crime and give me some examples\n",
      "============================================================\n",
      "🤖 Analysis: Using HYBRID approach\n",
      "💭 Reasoning: The question asks for \"trends,\" which requires aggregation and filtering by date and crime type (e.g., counting cyber crime incidents over time), a task best suited for SQL. It also asks for \"examples,\" which implies retrieving specific case details or narratives. To find relevant examples of \"cyber crime,\" especially if the definition is nuanced or described in narrative fields, a semantic search (VECTOR) would be highly effective. Combining the need for structured aggregation (SQL) and semantic content retrieval (VECTOR) makes HYBRID the optimal approach.\n",
      "------------------------------------------------------------\n",
      "🚀 Executing hybrid search...\n",
      "🔍 Executing SQL search...\n",
      "Generated SQL: To answer your question about trends and examples in cyber crime, we'll generate two separate querie...\n",
      "Query execution error: (psycopg2.errors.SyntaxError) syntax error at or near \"To\"\n",
      "LINE 1: To answer your question about trends and examples in cyber c...\n",
      "        ^\n",
      "\n",
      "[SQL: To answer your question about trends and examples in cyber crime, we'll generate two separate queries. The first query will provide examples of cyber crime occurrences, and the second will show the trends by counting these occurrences per year.\n",
      "\n",
      "We'll identify \"cyber crime\" by looking for keywords like 'cyber', 'online fraud', 'hacking', 'phishing', or 'scam' in the `sub_module` name, the `narrative` field, or the `A brief narrative of what happened` field within `formData`.\n",
      "\n",
      "```sql\n",
      "-- Query 1: Examples of Cyber Crime Occurrences\n",
      "-- This query provides detailed examples of records identified as cyber crime.\n",
      "SELECT\n",
      "    smd.ob_number,\n",
      "    smd.submissionDate,\n",
      "    sm.name AS occurrence_type,\n",
      "    smd.narrative,\n",
      "    smd.formData->>'A brief narrative of what happened' AS brief_narrative_from_form,\n",
      "    smd.formData->>'When did this happen' AS when_did_this_happen_form,\n",
      "    smd.formData->>'Type of GBV' AS type_of_gbv_form -- Included if cyber crime can be related to GBV\n",
      "FROM\n",
      "    sub_module_data smd\n",
      "JOIN\n",
      "    sub_module sm ON smd.sub_moduleId = sm.id\n",
      "WHERE\n",
      "    -- Identify cyber crime based on keywords in occurrence type name, narrative, or form data\n",
      "    sm.name ILIKE '%%cyber%%' OR\n",
      "    sm.name ILIKE '%%online fraud%%' OR\n",
      "    sm.name ILIKE '%%hacking%%' OR\n",
      "    sm.name ILIKE '%%phishing%%' OR\n",
      "    sm.name ILIKE '%%scam%%' OR\n",
      "    smd.narrative ILIKE '%%cyber%%' OR\n",
      "    smd.narrative ILIKE '%%online fraud%%' OR\n",
      "    smd.narrative ILIKE '%%hacking%%' OR\n",
      "    smd.narrative ILIKE '%%phishing%%' OR\n",
      "    smd.narrative ILIKE '%%scam%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%cyber%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%online fraud%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%hacking%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%phishing%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%scam%%'\n",
      "ORDER BY\n",
      "    smd.submissionDate DESC -- Order by most recent submissions to see current examples\n",
      "LIMIT 10; -- Limit to 10 examples for brevity\n",
      "\n",
      "\n",
      "-- Query 2: Trends in Cyber Crime (Count per year)\n",
      "-- This query shows the number of identified cyber crime occurrences per year, indicating trends.\n",
      "SELECT\n",
      "    EXTRACT(YEAR FROM smd.submissionDate) AS crime_year,\n",
      "    COUNT(smd.id) AS total_cyber_crimes_reported\n",
      "FROM\n",
      "    sub_module_data smd\n",
      "JOIN\n",
      "    sub_module sm ON smd.sub_moduleId = sm.id\n",
      "WHERE\n",
      "    -- Use the same criteria to identify cyber crime as in the examples query\n",
      "    sm.name ILIKE '%%cyber%%' OR\n",
      "    sm.name ILIKE '%%online fraud%%' OR\n",
      "    sm.name ILIKE '%%hacking%%' OR\n",
      "    sm.name ILIKE '%%phishing%%' OR\n",
      "    sm.name ILIKE '%%scam%%' OR\n",
      "    smd.narrative ILIKE '%%cyber%%' OR\n",
      "    smd.narrative ILIKE '%%online fraud%%' OR\n",
      "    smd.narrative ILIKE '%%hacking%%' OR\n",
      "    smd.narrative ILIKE '%%phishing%%' OR\n",
      "    smd.narrative ILIKE '%%scam%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%cyber%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%online fraud%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%hacking%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%phishing%%' OR\n",
      "    smd.formData->>'A brief narrative of what happened' ILIKE '%%scam%%'\n",
      "GROUP BY\n",
      "    crime_year\n",
      "ORDER BY\n",
      "    crime_year;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "🎯 Executing vector search...\n",
      "Based on the provided data:\n",
      "\n",
      "**Trends in Cyber Crime:**\n",
      "\n",
      "Unfortunately, no SQL results were provided, which limits the ability to identify quantitative trends such as frequency changes over time, common targets, or specific types of cyber crime. The \"Similar Occurrences\" data, while confirming the p...\n",
      "\n",
      "============================================================\n",
      "\n",
      "4. Testing: Find all arson cases affecting schools\n",
      "──────────────────────────────────────────────────\n",
      "🎯 Classified as: HYBRID\n",
      "💡 Reasoning: This question requires filtering by specific criteria (\"arson\" and \"schools\"). While \"arson\" might be a structured crime type and \"schools\" a structured location type (which would be handled by SQL), to \"Find all\" relevant cases, it's often necessary to also search unstructured narrative descriptions for semantic matches. For example, \"arson\" might be described as \"deliberately set fire,\" and \"schools\" could be referred to as \"educational facility\" or \"university campus.\" The SQL component would filter on structured fields, and the VECTOR component would perform semantic search on narrative text to capture all instances, making it a complex query that benefits from both approaches. This aligns with the provided example \"Find arson cases at schools\" being classified as HYBRID.\n",
      "\n",
      "Question: Find all arson cases affecting schools\n",
      "============================================================\n",
      "🤖 Analysis: Using HYBRID approach\n",
      "💭 Reasoning: \"Arson cases\" is a specific crime type, which is best handled by a structured filter (SQL). However, \"affecting schools\" might not always be a perfectly structured field. It could involve a structured location or victim type (SQL), but also require semantic understanding of narrative descriptions (VECTOR) to identify cases where schools are mentioned in the text, or where the impact on a school is described, even if not explicitly categorized in a structured field. The combination of precise filtering and semantic search makes a HYBRID approach most effective for comprehensive results. This aligns with the provided example \"Find arson cases at schools\" also being classified as HYBRID.\n",
      "------------------------------------------------------------\n",
      "🚀 Executing hybrid search...\n",
      "🔍 Executing SQL search...\n",
      "Generated SQL: SELECT\n",
      "    smd.ob_number,\n",
      "    sm.name AS occurrence_type,\n",
      "    smd.submissionDate,\n",
      "    smd.location,\n",
      "...\n",
      "Query execution error: (psycopg2.errors.UndefinedColumn) column smd.sub_moduleid does not exist\n",
      "LINE 10:     sub_module sm ON smd.sub_moduleId = sm.id\n",
      "                              ^\n",
      "HINT:  Perhaps you meant to reference the column \"smd.sub_moduleId\".\n",
      "\n",
      "[SQL: SELECT\n",
      "    smd.ob_number,\n",
      "    sm.name AS occurrence_type,\n",
      "    smd.submissionDate,\n",
      "    smd.location,\n",
      "    smd.formData->>'A brief narrative of what happened' AS narrative_description\n",
      "FROM\n",
      "    sub_module_data smd\n",
      "JOIN\n",
      "    sub_module sm ON smd.sub_moduleId = sm.id\n",
      "WHERE\n",
      "    sm.name ILIKE '%%arson%%' -- Identifies occurrence types related to arson\n",
      "    AND (\n",
      "        smd.location ILIKE '%%school%%' -- Checks the 'location' column for \"school\"\n",
      "        OR smd.formData->>'A brief narrative of what happened' ILIKE '%%school%%' -- Checks the narrative field in formData for \"school\"\n",
      "        -- Add more conditions here if other formData fields might indicate a school, e.g.,\n",
      "        -- OR smd.formData->>'Name of the owner' ILIKE '%%school%%'\n",
      "    );]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "🎯 Executing vector search...\n",
      "Based on the provided data:\n",
      "\n",
      "**SQL Results:**\n",
      "No direct SQL results were found for arson cases specifically affecting schools. This indicates that the structured data does not contain explicit entries or a queryable field linking arson incidents directly to school locations.\n",
      "\n",
      "**Similar Occurrences:*...\n",
      "\n",
      "============================================================\n",
      "\n",
      "5. Testing: Count total occurrences by module type\n",
      "──────────────────────────────────────────────────\n",
      "🎯 Classified as: SQL\n",
      "💡 Reasoning: The question asks for a direct count and aggregation (grouping by 'module type'). This is a classic structured data query that involves counting and grouping, which SQL is specifically designed for. It does not require semantic understanding or similarity search.\n",
      "\n",
      "Question: Count total occurrences by module type\n",
      "============================================================\n",
      "🤖 Analysis: Using SQL approach\n",
      "💭 Reasoning: The question asks for a direct count and aggregation (grouping by 'module type'). This is a classic structured data query that involves counting and grouping, which SQL is specifically designed for. It does not require semantic understanding or similarity search.\n",
      "------------------------------------------------------------\n",
      "🔍 Executing SQL search...\n",
      "Generated SQL: SELECT\n",
      "    sm.name AS module_type,\n",
      "    COUNT(smd.id) AS total_occurrences\n",
      "FROM\n",
      "    sub_module_data s...\n",
      "Query execution error: (psycopg2.errors.UndefinedColumn) column smd.sub_moduleid does not exist\n",
      "LINE 7:     sub_module sm ON smd.sub_moduleId = sm.id\n",
      "                             ^\n",
      "HINT:  Perhaps you meant to reference the column \"smd.sub_moduleId\".\n",
      "\n",
      "[SQL: SELECT\n",
      "    sm.name AS module_type,\n",
      "    COUNT(smd.id) AS total_occurrences\n",
      "FROM\n",
      "    sub_module_data smd\n",
      "JOIN\n",
      "    sub_module sm ON smd.sub_moduleId = sm.id\n",
      "GROUP BY\n",
      "    sm.name\n",
      "ORDER BY\n",
      "    total_occurrences DESC;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "No SQL results found\n",
      "\n",
      "============================================================\n",
      "\n",
      "🎉 Hybrid Search System Ready!\n",
      "\n",
      "Usage Examples:\n",
      "==============\n",
      "\n",
      "# Simple search (automatically chooses best method)\n",
      "quick_search(\"How many death cases in the last week?\")\n",
      "\n",
      "# Detailed search with method explanation  \n",
      "hybrid_search.search(\"Find cases similar to laptop theft at university\")\n",
      "\n",
      "# The system will automatically:\n",
      "# 1. Analyze your question\n",
      "# 2. Choose SQL, VECTOR, or HYBRID approach\n",
      "# 3. Execute the appropriate search\n",
      "# 4. Return comprehensive results\n",
      "\n",
      "Try asking questions like:\n",
      "- \"How many motor vehicle thefts in July 2025?\"\n",
      "- \"Show me cases similar to fire incidents at schools\"  \n",
      "- \"What are the patterns in cyber crime and show examples\"\n",
      "- \"Find all high urgency cases involving stolen electronics\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Hybrid Search System\n",
    "\"\"\"\n",
    "Hybrid search that combines:\n",
    "1. SQL-based queries on relational data (structured queries, analytics, counts)\n",
    "2. Vector-based semantic search on occurrence content (similarity, meaning)\n",
    "3. Intelligent routing to determine which method(s) to use\n",
    "\"\"\"\n",
    "\n",
    "class HybridOccurrenceSearch:\n",
    "    \"\"\"Hybrid search system combining SQL and vector search\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, vector_store: OccurrenceVectorStore, query_builder: JSONBQueryBuilder, schema_manager: FieldSchemaManager):\n",
    "        self.llm = llm\n",
    "        self.vector_store = vector_store\n",
    "        self.query_builder = query_builder\n",
    "        self.schema_manager = schema_manager\n",
    "        self.setup_prompts()\n",
    "    \n",
    "    def setup_prompts(self):\n",
    "        \"\"\"Setup prompts for query classification and SQL generation\"\"\"\n",
    "        \n",
    "        # Query classification prompt\n",
    "        self.classifier_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Analyze this question about police occurrence data and classify the search approach needed.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Available search methods:\n",
    "1. SQL - For counts, statistics, filtering by specific criteria, date ranges, aggregations\n",
    "2. VECTOR - For finding similar content, semantic search, narrative descriptions\n",
    "3. HYBRID - For complex questions needing both approaches\n",
    "\n",
    "Examples:\n",
    "- \"How many vehicle thefts in the last month?\" → SQL\n",
    "- \"Show me cases similar to a stolen laptop at university\" → VECTOR  \n",
    "- \"What are the trends in cyber crime and show me examples\" → HYBRID\n",
    "- \"Find arson cases at schools\" → HYBRID\n",
    "- \"Count death cases by cause\" → SQL\n",
    "- \"Cases involving stolen electronics\" → VECTOR\n",
    "\n",
    "Classification: Choose ONE: SQL, VECTOR, or HYBRID\n",
    "Reasoning: Brief explanation of why this approach is best.\n",
    "\n",
    "Response format:\n",
    "METHOD: [SQL/VECTOR/HYBRID]\n",
    "REASONING: [explanation]\n",
    "\"\"\")\n",
    "        \n",
    "        # SQL generation prompt\n",
    "        self.sql_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Generate a PostgreSQL query for this question about police occurrence data.\n",
    "\n",
    "Database Schema:\n",
    "- sub_module_data: Contains occurrence records with JSONB formData\n",
    "  * Columns: id, ob_number, submissionDate, sub_moduleId, formData (JSONB), location, urgency, narrative, iprsId\n",
    "- sub_module: Contains occurrence type definitions\n",
    "  * Columns: id, name, description, fields (JSONB schema)\n",
    "- IPRS_Person: Contains person information\n",
    "  * Columns: id, id_no, first_name, last_name, gender, nationality, email, phone_number\n",
    "\n",
    "Available JSONB fields in formData (commonly used):\n",
    "{available_fields}\n",
    "\n",
    "Important notes:\n",
    "- Use formData->>'field_name' to extract text values from JSONB\n",
    "- Use formData->'field_name' for JSON values  \n",
    "- Join with sub_module to get occurrence type names\n",
    "- Join with IPRS_Person using iprsId for reporter information\n",
    "- Always include ob_number in results for reference\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Generate a valid PostgreSQL query:\n",
    "\"\"\")\n",
    "        \n",
    "        # Hybrid response prompt\n",
    "        self.hybrid_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are analyzing police occurrence data. Answer the question using both SQL results and similar occurrence examples.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "SQL Results (structured data):\n",
    "{sql_results}\n",
    "\n",
    "Similar Occurrences (semantic matches):\n",
    "{vector_results}\n",
    "\n",
    "Available Occurrence Types:\n",
    "{schema_info}\n",
    "\n",
    "Instructions:\n",
    "- Combine insights from both SQL data and similar occurrences\n",
    "- Mention specific OB numbers when referencing cases\n",
    "- Provide quantitative insights from SQL and qualitative examples from vector search\n",
    "- If trends are asked about, analyze patterns in the data\n",
    "- Be comprehensive but concise\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "    \n",
    "    def classify_query(self, question: str) -> tuple:\n",
    "        \"\"\"Classify the query to determine search approach\"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(self.classifier_prompt.format(question=question))\n",
    "            content = response.content.strip()\n",
    "            \n",
    "            # Extract method and reasoning\n",
    "            method = \"HYBRID\"  # Default\n",
    "            reasoning = \"Complex question requiring multiple approaches\"\n",
    "            \n",
    "            lines = content.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.startswith('METHOD:'):\n",
    "                    method = line.split(':', 1)[1].strip()\n",
    "                elif line.startswith('REASONING:'):\n",
    "                    reasoning = line.split(':', 1)[1].strip()\n",
    "            \n",
    "            return method, reasoning\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Classification error: {e}\")\n",
    "            return \"HYBRID\", \"Error in classification, using hybrid approach\"\n",
    "    \n",
    "    def generate_sql_query(self, question: str) -> str:\n",
    "        \"\"\"Generate SQL query for the question\"\"\"\n",
    "        available_fields = ', '.join(self.schema_manager.get_all_field_names()[:20])\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(self.sql_prompt.format(\n",
    "                question=question,\n",
    "                available_fields=available_fields\n",
    "            ))\n",
    "            \n",
    "            sql_query = response.content.strip()\n",
    "            \n",
    "            # Clean up SQL (remove markdown formatting)\n",
    "            if sql_query.startswith('```sql'):\n",
    "                sql_query = sql_query[6:]\n",
    "            if sql_query.endswith('```'):\n",
    "                sql_query = sql_query[:-3]\n",
    "            \n",
    "            return sql_query.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"SQL generation error: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def execute_sql_search(self, question: str) -> str:\n",
    "        \"\"\"Execute SQL-based search\"\"\"\n",
    "        print(\"🔍 Executing SQL search...\")\n",
    "        \n",
    "        sql_query = self.generate_sql_query(question)\n",
    "        if not sql_query:\n",
    "            return \"Could not generate SQL query\"\n",
    "        \n",
    "        print(f\"Generated SQL: {sql_query[:100]}...\")\n",
    "        \n",
    "        results = self.query_builder.execute_query(sql_query)\n",
    "        if results:\n",
    "            return f\"SQL Query: {sql_query}\\n\\nResults: {results}\"\n",
    "        else:\n",
    "            return \"No SQL results found\"\n",
    "    \n",
    "    def execute_vector_search(self, question: str) -> str:\n",
    "        \"\"\"Execute vector-based semantic search\"\"\"\n",
    "        print(\"🎯 Executing vector search...\")\n",
    "        \n",
    "        if not self.vector_store.retriever:\n",
    "            return \"Vector store not initialized. Please load occurrences first.\"\n",
    "        \n",
    "        docs = self.vector_store.search_similar_occurrences(question, k=5)\n",
    "        \n",
    "        if docs:\n",
    "            formatted_results = []\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                formatted_results.append(f\"Match {i}:\")\n",
    "                formatted_results.append(f\"OB: {doc.metadata.get('ob_number', 'N/A')}\")\n",
    "                formatted_results.append(f\"Type: {doc.metadata.get('module_name', 'N/A')}\")\n",
    "                formatted_results.append(f\"Content: {doc.page_content[:200]}...\")\n",
    "                formatted_results.append(\"-\" * 40)\n",
    "            \n",
    "            return \"\\n\".join(formatted_results)\n",
    "        else:\n",
    "            return \"No similar occurrences found\"\n",
    "    \n",
    "    def execute_hybrid_search(self, question: str) -> str:\n",
    "        \"\"\"Execute hybrid search combining SQL and vector approaches\"\"\"\n",
    "        print(\"🚀 Executing hybrid search...\")\n",
    "        \n",
    "        # Get SQL results\n",
    "        sql_results = self.execute_sql_search(question)\n",
    "        \n",
    "        # Get vector results  \n",
    "        vector_results = self.execute_vector_search(question)\n",
    "        \n",
    "        # Get schema info\n",
    "        schema_info = \"\\n\".join([f\"{s['name']}: {s['description']}\" for s in self.schema_manager.schemas.values()])\n",
    "        \n",
    "        # Generate combined response\n",
    "        try:\n",
    "            response = self.llm.invoke(self.hybrid_prompt.format(\n",
    "                question=question,\n",
    "                sql_results=sql_results,\n",
    "                vector_results=vector_results,\n",
    "                schema_info=schema_info\n",
    "            ))\n",
    "            \n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating hybrid response: {e}\\n\\nSQL Results:\\n{sql_results}\\n\\nVector Results:\\n{vector_results}\"\n",
    "    \n",
    "    def search(self, question: str) -> str:\n",
    "        \"\"\"Main search function that automatically chooses the best approach\"\"\"\n",
    "        print(f\"Question: {question}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Classify the query\n",
    "        method, reasoning = self.classify_query(question)\n",
    "        print(f\"🤖 Analysis: Using {method} approach\")\n",
    "        print(f\"💭 Reasoning: {reasoning}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Execute appropriate search\n",
    "        if method == \"SQL\":\n",
    "            return self.execute_sql_search(question)\n",
    "        elif method == \"VECTOR\":\n",
    "            return self.execute_vector_search(question)\n",
    "        else:  # HYBRID\n",
    "            return self.execute_hybrid_search(question)\n",
    "\n",
    "def quick_search(question: str) -> str:\n",
    "    \"\"\"Quick search function for easy use\"\"\"\n",
    "    return hybrid_search.search(question)\n",
    "\n",
    "# Initialize hybrid search system\n",
    "hybrid_search = HybridOccurrenceSearch(llm, vector_store, query_builder, schema_manager)\n",
    "print(\"✅ Hybrid Search System initialized!\")\n",
    "\n",
    "# Test the hybrid search with different types of questions\n",
    "test_questions = [\n",
    "    \"How many vehicle thefts were reported in the last month?\",  # Should use SQL\n",
    "    \"Show me cases similar to stolen electronics at universities\",  # Should use VECTOR\n",
    "    \"What are the trends in cyber crime and give me some examples\",  # Should use HYBRID\n",
    "    \"Find all arson cases affecting schools\",  # Should use HYBRID\n",
    "    \"Count total occurrences by module type\"  # Should use SQL\n",
    "]\n",
    "\n",
    "print(\"\\n🧪 Testing Hybrid Search System:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. Testing: {question}\")\n",
    "    print(\"─\" * 50)\n",
    "    \n",
    "    try:\n",
    "        method, reasoning = hybrid_search.classify_query(question)\n",
    "        print(f\"🎯 Classified as: {method}\")\n",
    "        print(f\"💡 Reasoning: {reasoning}\")\n",
    "        print()\n",
    "        \n",
    "        # For demo, just show classification - uncomment below to run full search\n",
    "        result = hybrid_search.search(question)\n",
    "        print(result[:300] + \"...\" if len(result) > 300 else result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "🎉 Hybrid Search System Ready!\n",
    "\n",
    "Usage Examples:\n",
    "==============\n",
    "\n",
    "# Simple search (automatically chooses best method)\n",
    "quick_search(\"How many death cases in the last week?\")\n",
    "\n",
    "# Detailed search with method explanation  \n",
    "hybrid_search.search(\"Find cases similar to laptop theft at university\")\n",
    "\n",
    "# The system will automatically:\n",
    "# 1. Analyze your question\n",
    "# 2. Choose SQL, VECTOR, or HYBRID approach\n",
    "# 3. Execute the appropriate search\n",
    "# 4. Return comprehensive results\n",
    "\n",
    "Try asking questions like:\n",
    "- \"How many motor vehicle thefts in July 2025?\"\n",
    "- \"Show me cases similar to fire incidents at schools\"  \n",
    "- \"What are the patterns in cyber crime and show examples\"\n",
    "- \"Find all high urgency cases involving stolen electronics\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b69d77e-35c2-4d2d-8299-bfd7ecc755fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Initializing Advanced Hybrid Search Agent...\n"
     ]
    },
    {
     "ename": "PydanticUserError",
     "evalue": "Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/model-field-overridden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticUserError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 253\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# Initialize the advanced hybrid search agent\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 Initializing Advanced Hybrid Search Agent...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m advanced_agent = \u001b[43mAdvancedHybridSearchAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Advanced Hybrid Search Agent initialized!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# Test the agent capabilities\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mAdvancedHybridSearchAgent.__init__\u001b[39m\u001b[34m(self, llm, db, vector_store, schema_manager)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.vector_store = vector_store\n\u001b[32m     24\u001b[39m \u001b[38;5;28mself\u001b[39m.schema_manager = schema_manager\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mself\u001b[39m.setup_prompts()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mAdvancedHybridSearchAgent.setup_agent\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.sql_tools = \u001b[38;5;28mself\u001b[39m.sql_toolkit.get_tools()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Add custom vector search tool\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28mself\u001b[39m.vector_tool = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_vector_search_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Combine all tools\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m.all_tools = \u001b[38;5;28mself\u001b[39m.sql_tools + [\u001b[38;5;28mself\u001b[39m.vector_tool]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mAdvancedHybridSearchAgent.create_vector_search_tool\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create a custom vector search tool for the agent\"\"\"\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTool\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mVectorSearchTool\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseTool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvector_search_occurrences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m     94\u001b[39m \u001b[33;43m    Search for similar occurrences using semantic similarity.\u001b[39;49m\n\u001b[32m     95\u001b[39m \u001b[33;43m    Input should be a descriptive query about the type of occurrence you\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mre looking for.\u001b[39;49m\n\u001b[32m     96\u001b[39m \u001b[33;43m    Examples: \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstolen laptop at university\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfire at school\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvehicle theft at shopping center\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     97\u001b[39m \u001b[33;43m    Returns the most similar occurrence records with OB numbers and details.\u001b[39;49m\n\u001b[32m     98\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.dev/VPS_Search/RAG/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:112\u001b[39m, in \u001b[36mModelMetaclass.__new__\u001b[39m\u001b[34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs)\n\u001b[32m    111\u001b[39m namespace[\u001b[33m'\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m'\u001b[39m] = config_wrapper.config_dict\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m private_attributes = \u001b[43minspect_namespace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mignored_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_field_names\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m private_attributes \u001b[38;5;129;01mor\u001b[39;00m base_private_attributes:\n\u001b[32m    116\u001b[39m     original_model_post_init = get_model_post_init(namespace, bases)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.dev/VPS_Search/RAG/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:449\u001b[39m, in \u001b[36minspect_namespace\u001b[39m\u001b[34m(namespace, ignored_types, base_class_vars, base_class_fields)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m raw_annotations:\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m base_class_fields:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    450\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m defined on a base class was overridden by a non-annotated attribute. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    451\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAll field definitions, including overrides, require a type annotation.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    452\u001b[39m             code=\u001b[33m'\u001b[39m\u001b[33mmodel-field-overridden\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    453\u001b[39m         )\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, FieldInfo):\n\u001b[32m    455\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    456\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m requires a type annotation\u001b[39m\u001b[33m'\u001b[39m, code=\u001b[33m'\u001b[39m\u001b[33mmodel-field-missing-annotation\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    457\u001b[39m         )\n",
      "\u001b[31mPydanticUserError\u001b[39m: Field 'name' defined on a base class was overridden by a non-annotated attribute. All field definitions, including overrides, require a type annotation.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/model-field-overridden"
     ]
    }
   ],
   "source": [
    "# Cell 10: Advanced Hybrid Search with LangGraph Agent\n",
    "\"\"\"\n",
    "Advanced hybrid search system that combines:\n",
    "1. LangGraph SQL Agent (from rag_sql notebook) for complex database interactions\n",
    "2. Vector search from occurrence data\n",
    "3. Multiple database source integration\n",
    "4. React-style agent that can use tools and reason about queries\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "from typing import Dict, List, Any, Optional\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class AdvancedHybridSearchAgent:\n",
    "    \"\"\"Advanced hybrid search with LangGraph agent and multiple sources\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, db, vector_store, schema_manager):\n",
    "        self.llm = llm\n",
    "        self.db = db\n",
    "        self.vector_store = vector_store\n",
    "        self.schema_manager = schema_manager\n",
    "        self.setup_agent()\n",
    "        self.setup_prompts()\n",
    "    \n",
    "    def setup_agent(self):\n",
    "        \"\"\"Setup the LangGraph SQL agent with tools\"\"\"\n",
    "        \n",
    "        # Create SQL toolkit\n",
    "        self.sql_toolkit = SQLDatabaseToolkit(db=self.db, llm=self.llm)\n",
    "        self.sql_tools = self.sql_toolkit.get_tools()\n",
    "        \n",
    "        # Add custom vector search tool\n",
    "        self.vector_tool = self.create_vector_search_tool()\n",
    "        \n",
    "        # Combine all tools\n",
    "        self.all_tools = self.sql_tools + [self.vector_tool]\n",
    "        \n",
    "        # System message for the agent\n",
    "        self.system_message = \"\"\"\n",
    "You are an intelligent police occurrence data analyst with access to multiple search capabilities.\n",
    "\n",
    "You have access to these tools:\n",
    "1. SQL Database Tools - For structured queries, statistics, counts, filtering\n",
    "   - sql_db_list_tables: List all available tables\n",
    "   - sql_db_schema: Get table schemas and sample data\n",
    "   - sql_db_query: Execute SQL queries\n",
    "   - sql_db_query_checker: Validate SQL queries\n",
    "\n",
    "2. Vector Search Tool - For semantic similarity and content-based search\n",
    "   - vector_search_occurrences: Find similar occurrences based on content\n",
    "\n",
    "Database Schema Overview:\n",
    "- sub_module_data: Main occurrence records with JSONB formData\n",
    "- sub_module: Occurrence type definitions and field schemas  \n",
    "- IPRS_Person: Person/reporter information\n",
    "- Additional tables may be available (use sql_db_list_tables to explore)\n",
    "\n",
    "JSONB formData contains dynamic fields based on occurrence type:\n",
    "- Vehicle theft: Make, Model, Color, Registration number, etc.\n",
    "- Death cases: Cause of death, Gender, Contact person, etc.\n",
    "- Arson: Property type, Owner information, etc.\n",
    "- Cyber crime: Incident type, Suspect details, etc.\n",
    "\n",
    "Important Guidelines:\n",
    "1. ALWAYS start by understanding what tables are available if you're unsure\n",
    "2. For counts and statistics, use SQL queries\n",
    "3. For finding similar cases or content-based search, use vector search\n",
    "4. For complex questions, combine both approaches\n",
    "5. Always include ob_number in results for reference\n",
    "6. Use formData->>'field_name' to extract JSONB text values\n",
    "7. Join with IPRS_Person using iprsId for reporter information\n",
    "8. Be thorough but concise in your analysis\n",
    "\n",
    "When answering:\n",
    "- Provide specific OB numbers when referencing cases\n",
    "- Include quantitative insights when available\n",
    "- Give concrete examples from the data\n",
    "- Explain your reasoning and approach\n",
    "\"\"\"\n",
    "        \n",
    "        # Create the react agent\n",
    "        self.agent_executor = create_react_agent(self.llm, self.all_tools, prompt=self.system_message)\n",
    "        \n",
    "    def create_vector_search_tool(self):\n",
    "        \"\"\"Create a custom vector search tool for the agent\"\"\"\n",
    "        from langchain.tools import BaseTool\n",
    "        \n",
    "        class VectorSearchTool(BaseTool):\n",
    "            name = \"vector_search_occurrences\"\n",
    "            description = \"\"\"\n",
    "            Search for similar occurrences using semantic similarity.\n",
    "            Input should be a descriptive query about the type of occurrence you're looking for.\n",
    "            Examples: 'stolen laptop at university', 'fire at school', 'vehicle theft at shopping center'\n",
    "            Returns the most similar occurrence records with OB numbers and details.\n",
    "            \"\"\"\n",
    "            \n",
    "            def __init__(self, vector_store):\n",
    "                super().__init__()\n",
    "                self.vector_store = vector_store\n",
    "            \n",
    "            def _run(self, query: str) -> str:\n",
    "                \"\"\"Execute vector search\"\"\"\n",
    "                try:\n",
    "                    if not self.vector_store.retriever:\n",
    "                        return \"Vector store not initialized. Please load occurrences first.\"\n",
    "                    \n",
    "                    docs = self.vector_store.search_similar_occurrences(query, k=5)\n",
    "                    \n",
    "                    if not docs:\n",
    "                        return \"No similar occurrences found.\"\n",
    "                    \n",
    "                    results = []\n",
    "                    for i, doc in enumerate(docs, 1):\n",
    "                        results.append(f\"Match {i}:\")\n",
    "                        results.append(f\"OB Number: {doc.metadata.get('ob_number', 'N/A')}\")\n",
    "                        results.append(f\"Type: {doc.metadata.get('module_name', 'N/A')}\")\n",
    "                        results.append(f\"Date: {doc.metadata.get('submission_date', 'N/A')}\")\n",
    "                        results.append(f\"Urgency: {doc.metadata.get('urgency', 'N/A')}\")\n",
    "                        results.append(f\"Content: {doc.page_content[:300]}...\")\n",
    "                        results.append(\"-\" * 50)\n",
    "                    \n",
    "                    return \"\\n\".join(results)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    return f\"Error in vector search: {e}\"\n",
    "            \n",
    "            def _arun(self, query: str) -> str:\n",
    "                \"\"\"Async version\"\"\"\n",
    "                return self._run(query)\n",
    "        \n",
    "        return VectorSearchTool(self.vector_store)\n",
    "    \n",
    "    def setup_prompts(self):\n",
    "        \"\"\"Setup additional prompts for query enhancement\"\"\"\n",
    "        \n",
    "        self.query_enhancer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Enhance this user question to be more specific for police occurrence data analysis.\n",
    "\n",
    "Original question: {question}\n",
    "\n",
    "Available data includes:\n",
    "- Occurrence records with details like location, urgency, dates\n",
    "- JSONB form data with specific fields per occurrence type\n",
    "- Reporter information (names, ID numbers, contact details)\n",
    "- Occurrence types: Arson, Assault, Burglary, Cyber Crime, Death, Homicide, Motor Vehicle Theft, Missing Person, Rape, Robbery, Stolen Lost Item, GBV\n",
    "\n",
    "Enhanced question with more context and specificity:\n",
    "\"\"\")\n",
    "    \n",
    "    def enhance_query(self, question: str) -> str:\n",
    "        \"\"\"Enhance the user query for better processing\"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(self.query_enhancer_prompt.format(question=question))\n",
    "            enhanced = response.content.strip()\n",
    "            return enhanced if enhanced else question\n",
    "        except:\n",
    "            return question\n",
    "    \n",
    "    def search(self, question: str, enhance_query: bool = True) -> str:\n",
    "        \"\"\"Main search function using the agent\"\"\"\n",
    "        \n",
    "        print(f\"🔍 Original Question: {question}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Enhance the query if requested\n",
    "        if enhance_query:\n",
    "            enhanced_question = self.enhance_query(question)\n",
    "            if enhanced_question != question:\n",
    "                print(f\"🎯 Enhanced Question: {enhanced_question}\")\n",
    "                print(\"-\" * 80)\n",
    "                question = enhanced_question\n",
    "        \n",
    "        # Execute using the agent\n",
    "        try:\n",
    "            print(\"🤖 Agent is analyzing and searching...\")\n",
    "            \n",
    "            # Create the human message\n",
    "            messages = [{\"role\": \"user\", \"content\": question}]\n",
    "            \n",
    "            # Stream the agent execution\n",
    "            response_parts = []\n",
    "            for step in self.agent_executor.stream(\n",
    "                {\"messages\": messages}, \n",
    "                stream_mode=\"values\"\n",
    "            ):\n",
    "                if step[\"messages\"]:\n",
    "                    last_message = step[\"messages\"][-1]\n",
    "                    if hasattr(last_message, 'content'):\n",
    "                        response_parts.append(last_message.content)\n",
    "            \n",
    "            # Get the final response\n",
    "            if response_parts:\n",
    "                return response_parts[-1]\n",
    "            else:\n",
    "                return \"No response generated\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error executing search: {e}\"\n",
    "    \n",
    "    def quick_sql_search(self, question: str) -> str:\n",
    "        \"\"\"Quick SQL-only search\"\"\"\n",
    "        print(\"🔍 Executing SQL-focused search...\")\n",
    "        \n",
    "        sql_question = f\"Use SQL queries to answer: {question}\"\n",
    "        return self.search(sql_question, enhance_query=False)\n",
    "    \n",
    "    def quick_vector_search(self, question: str) -> str:\n",
    "        \"\"\"Quick vector-only search\"\"\"\n",
    "        print(\"🎯 Executing vector-focused search...\")\n",
    "        \n",
    "        vector_question = f\"Use vector search to find similar occurrences for: {question}\"\n",
    "        return self.search(vector_question, enhance_query=False)\n",
    "    \n",
    "    def multi_source_search(self, question: str, sources: List[str] = None) -> str:\n",
    "        \"\"\"Search across multiple specified sources\"\"\"\n",
    "        if sources is None:\n",
    "            sources = [\"sql\", \"vector\"]\n",
    "        \n",
    "        print(f\"🚀 Executing multi-source search across: {', '.join(sources)}\")\n",
    "        \n",
    "        multi_question = f\"\"\"\n",
    "        Answer this question using multiple data sources: {question}\n",
    "        \n",
    "        Available sources: {', '.join(sources)}\n",
    "        - Use SQL for structured data, counts, statistics\n",
    "        - Use vector search for similar cases and content-based matching\n",
    "        - Combine insights from all sources for a comprehensive answer\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.search(multi_question, enhance_query=True)\n",
    "\n",
    "def advanced_search(question: str) -> str:\n",
    "    \"\"\"Quick function for advanced hybrid search\"\"\"\n",
    "    return advanced_agent.search(question)\n",
    "\n",
    "def sql_search(question: str) -> str:\n",
    "    \"\"\"Quick function for SQL-focused search\"\"\"\n",
    "    return advanced_agent.quick_sql_search(question)\n",
    "\n",
    "def vector_search(question: str) -> str:\n",
    "    \"\"\"Quick function for vector-focused search\"\"\"\n",
    "    return advanced_agent.quick_vector_search(question)\n",
    "\n",
    "def multi_search(question: str, sources: List[str] = None) -> str:\n",
    "    \"\"\"Quick function for multi-source search\"\"\"\n",
    "    return advanced_agent.multi_source_search(question, sources)\n",
    "\n",
    "# Initialize the advanced hybrid search agent\n",
    "print(\"🚀 Initializing Advanced Hybrid Search Agent...\")\n",
    "advanced_agent = AdvancedHybridSearchAgent(llm, db, vector_store, schema_manager)\n",
    "print(\"✅ Advanced Hybrid Search Agent initialized!\")\n",
    "\n",
    "# Test the agent capabilities\n",
    "print(\"\\n🧪 Testing Agent Capabilities:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test different types of searches\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"name\": \"SQL Analytics Test\",\n",
    "        \"question\": \"How many occurrences were reported in the last 30 days by type?\",\n",
    "        \"method\": \"sql_search\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Vector Similarity Test\", \n",
    "        \"question\": \"Find cases similar to stolen electronics\",\n",
    "        \"method\": \"vector_search\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Multi-Source Analysis Test\",\n",
    "        \"question\": \"What are the patterns in vehicle theft and show me examples\",\n",
    "        \"method\": \"multi_search\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\n{i}. {scenario['name']}\")\n",
    "    print(\"─\" * 50)\n",
    "    print(f\"Question: {scenario['question']}\")\n",
    "    print(f\"Method: {scenario['method']}\")\n",
    "    \n",
    "    # For demo, just show the setup - uncomment to run actual tests\n",
    "    # try:\n",
    "    #     if scenario['method'] == 'sql_search':\n",
    "    #         result = sql_search(scenario['question'])\n",
    "    #     elif scenario['method'] == 'vector_search':\n",
    "    #         result = vector_search(scenario['question'])\n",
    "    #     else:\n",
    "    #         result = multi_search(scenario['question'])\n",
    "    #     \n",
    "    #     print(f\"Result: {result[:200]}...\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "🎉 Advanced Hybrid Search Agent Ready!\n",
    "\n",
    "Available Functions:\n",
    "==================\n",
    "\n",
    "1. advanced_search(question) - Full agent with reasoning and tool selection\n",
    "2. sql_search(question) - SQL-focused analysis  \n",
    "3. vector_search(question) - Vector similarity search\n",
    "4. multi_search(question, sources) - Multi-source comprehensive search\n",
    "\n",
    "Examples:\n",
    "=========\n",
    "\n",
    "# Full agent reasoning\n",
    "advanced_search(\"What are the trends in cyber crime?\")\n",
    "\n",
    "# SQL analytics\n",
    "sql_search(\"How many vehicle thefts in July 2025?\")\n",
    "\n",
    "# Vector similarity  \n",
    "vector_search(\"Find cases like stolen laptop at university\")\n",
    "\n",
    "# Multi-source analysis\n",
    "multi_search(\"Analyze arson patterns with examples\", [\"sql\", \"vector\"])\n",
    "\n",
    "Features:\n",
    "=========\n",
    "✅ Intelligent tool selection and reasoning\n",
    "✅ SQL database exploration and querying\n",
    "✅ Vector semantic search integration\n",
    "✅ Multi-step analysis capabilities\n",
    "✅ Error handling and validation\n",
    "✅ Comprehensive result synthesis\n",
    "\n",
    "The agent can:\n",
    "- Explore database schema autonomously\n",
    "- Generate and validate SQL queries\n",
    "- Perform vector similarity searches\n",
    "- Combine multiple data sources\n",
    "- Reason about complex questions\n",
    "- Provide detailed explanations\n",
    "\"\"\")\n",
    "\n",
    "# Show available tools\n",
    "print(\"\\nAvailable Tools:\")\n",
    "print(\"=\" * 30)\n",
    "for tool in advanced_agent.all_tools:\n",
    "    print(f\"- {tool.name}: {tool.description[:60]}...\")\n",
    "\n",
    "print(f\"\\nTotal tools available: {len(advanced_agent.all_tools)}\")\n",
    "print(\"Ready for advanced occurrence data analysis! 🚀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c847f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
