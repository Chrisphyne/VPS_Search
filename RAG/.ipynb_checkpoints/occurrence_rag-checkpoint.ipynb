{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2baa8e2-5fc4-4272-b15e-35b2aea517ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: psycopg2-binary in ./.venv/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: langchain-google-genai in ./.venv/lib/python3.12/site-packages (2.1.9)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.12/site-packages (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.4.11)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (0.6.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (0.2.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.12/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.14.1)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm>=4.65.0 (from chromadb)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.12/site-packages (from chromadb) (3.11.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (4.25.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.31.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./.venv/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=75ea95d77879648179463b32e858bcf506e13bada8a697b9d376c7baa2a6593e\n",
      "  Stored in directory: /home/chris/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pytz, pypika, mpmath, flatbuffers, durationpy, zipp, websockets, uvloop, tzdata, tqdm, sympy, shellingham, pyproject_hooks, pybase64, opentelemetry-proto, oauthlib, mmh3, mdurl, importlib-resources, humanfriendly, httptools, hf-xet, fsspec, filelock, distro, click, bcrypt, backoff, watchfiles, uvicorn, requests-oauthlib, posthog, pandas, opentelemetry-exporter-otlp-proto-common, markdown-it-py, importlib-metadata, huggingface-hub, coloredlogs, build, tokenizers, rich, opentelemetry-api, onnxruntime, kubernetes, typer, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 build-1.3.0 chromadb-1.0.15 click-8.2.1 coloredlogs-15.0.1 distro-1.9.0 durationpy-0.10 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.7.0 hf-xet-1.1.5 httptools-0.6.4 huggingface-hub-0.34.3 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-33.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 oauthlib-3.3.1 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 pandas-2.3.1 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pytz-2025.2 requests-oauthlib-2.0.0 rich-14.1.0 shellingham-1.5.4 sympy-1.14.0 tokenizers-0.21.4 tqdm-4.67.1 typer-0.16.0 tzdata-2025.2 uvicorn-0.35.0 uvloop-0.21.0 watchfiles-1.1.0 websockets-15.0.1 zipp-3.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community langgraph psycopg2-binary langchain-google-genai pandas numpy chromadb langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa78569-d117-4827-af7a-4dcd7ddf9996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "\"\"\"\n",
    "Enhanced RAG System for JSONB Occurrence Data\n",
    "=============================================\n",
    "\n",
    "This system demonstrates how to make your JSONB occurrence data intelligently \n",
    "available to your LLM with field schema understanding.\n",
    "\n",
    "Key Features:\n",
    "- Dynamic field schema loading from sub_module table\n",
    "- Smart JSONB querying with field-aware SQL generation  \n",
    "- Vector search on occurrence content for semantic similarity\n",
    "- Field-aware LLM responses that understand your data structure\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain and AI imports\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4476b-82b5-4dfc-afa0-432553007f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Environment Configuration\n",
    "\"\"\"\n",
    "Configure environment variables and initialize database/AI connections\n",
    "\"\"\"\n",
    "\n",
    "# Set up environment variables\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyDsJJu5oN0BQrEKvnotU6uYEl5Mxw9fiug'\n",
    "#os.environ['GOOGLE_API_KEY'] = 'AIzaSyBwM-8qWcUoYY5TjQZYunatHsF3RGspoJo'\n",
    "os.environ['LANGSMITH_API_KEY'] = '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'\n",
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "\n",
    "# Database connection settings\n",
    "os.environ['DB_HOST'] = 'localhost'\n",
    "os.environ['DB_PORT'] = '5432'\n",
    "os.environ['DB_NAME'] = 'obmain'\n",
    "os.environ['DB_USER'] = 'myuser'\n",
    "os.environ['DB_PASSWORD'] = 'Welcome123'\n",
    "\n",
    "# Initialize database connection\n",
    "db_uri = f\"postgresql://{os.environ['DB_USER']}:{os.environ['DB_PASSWORD']}@{os.environ['DB_HOST']}:{os.environ['DB_PORT']}/{os.environ['DB_NAME']}\"\n",
    "\n",
    "try:\n",
    "    db = SQLDatabase.from_uri(db_uri)\n",
    "    print(\"✅ Database connected successfully!\")\n",
    "    print(f\"Available tables: {db.get_usable_table_names()}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Database connection failed: {e}\")\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "print(\"✅ LLM and embeddings initialized!\")\n",
    "print(\"✅ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "895e86de-7ce2-46c5-b2ff-838511c7fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded schemas for 16 modules\n",
      "✅ Field Schema Manager initialized!\n",
      "\n",
      "Available Occurrence Types and Sample Fields:\n",
      "============================================================\n",
      "\n",
      "1. Arson\n",
      "   Description: Vandalizing or damaging by burning down\n",
      "   Total fields: 8\n",
      "   Sample fields:\n",
      "     - Give a brief narrative of what happened (narrative)\n",
      "     - Type of property (select)\n",
      "     - Plot No (text)\n",
      "     ... and 5 more fields\n",
      "\n",
      "2. Assault\n",
      "   Description: Attack by a person on another\n",
      "   Total fields: 10\n",
      "   Sample fields:\n",
      "     - Who was assaulted (select)\n",
      "     - Name of the victim (text)\n",
      "     - Gender of the victim (select)\n",
      "     ... and 7 more fields\n",
      "\n",
      "3. Burglary\n",
      "   Description: Unlawful or forced entry into a building to commit a crime\n",
      "   Total fields: 31\n",
      "   Sample fields:\n",
      "     - select type of property broken into (single-choice)\n",
      "     - Property Name (tetx)\n",
      "     - LR Number (tetx)\n",
      "     ... and 28 more fields\n",
      "\n",
      "4. Cyber Crime\n",
      "   Description: Criminal activity that are carried out using digital devices and networks\n",
      "   Total fields: 8\n",
      "   Sample fields:\n",
      "     - Select Incident (select)\n",
      "     - Who is the victim (single-choice)\n",
      "     - Relationship (select)\n",
      "     ... and 5 more fields\n",
      "\n",
      "5. Death\n",
      "   Description: Death\n",
      "   Total fields: 11\n",
      "   Sample fields:\n",
      "     - Who is dead (select)\n",
      "     - Name (text)\n",
      "     - Age (select)\n",
      "     ... and 8 more fields\n",
      "\n",
      "6. Homicide\n",
      "   Description: Intentional murder manslaughter or killing of a person\n",
      "   Total fields: 9\n",
      "   Sample fields:\n",
      "     - Who is dead (select)\n",
      "     - Name of the deceased (text)\n",
      "     - Gender of deceased (select)\n",
      "     ... and 6 more fields\n",
      "\n",
      "8. Motor Vehicle Theft\n",
      "   Description: Motor Vehicle Theft\n",
      "   Total fields: 8\n",
      "   Sample fields:\n",
      "     - Body type (select)\n",
      "     - Registration number (text)\n",
      "     - Make (select)\n",
      "     ... and 5 more fields\n",
      "\n",
      "9. Rape\n",
      "   Description: Rape\n",
      "   Total fields: 14\n",
      "   Sample fields:\n",
      "     - Who was raped (single-choice)\n",
      "     - Name (text)\n",
      "     - Gender (select)\n",
      "     ... and 11 more fields\n",
      "\n",
      "7. Missing Person\n",
      "   Description: Missing Person\n",
      "   Total fields: 14\n",
      "   Sample fields:\n",
      "     - Who is missing (single-choice)\n",
      "     - Name (text)\n",
      "     - Gender (select)\n",
      "     ... and 11 more fields\n",
      "\n",
      "10. Robbery\n",
      "   Description: Robbery\n",
      "   Total fields: 26\n",
      "   Sample fields:\n",
      "     - What category of items were stolen (multi-select)\n",
      "     - type of electronic (multi-select)\n",
      "     - Television serial number (text)\n",
      "     ... and 23 more fields\n",
      "\n",
      "12. GBV\n",
      "   Description: gender based violence\n",
      "   Total fields: 23\n",
      "   Sample fields:\n",
      "     - Type of GBV (single-choice)\n",
      "     - Sexual Violence (select)\n",
      "     - Physical Violence (select)\n",
      "     ... and 20 more fields\n",
      "\n",
      "11. Stolen Lost Item\n",
      "   Description: Stolen Lost Item\n",
      "   Total fields: 22\n",
      "   Sample fields:\n",
      "     - What category of items were stolen (multi-select)\n",
      "     - type of electronic (multi-select)\n",
      "     - Television serial number (text)\n",
      "     ... and 19 more fields\n",
      "\n",
      "13. Visits\n",
      "   Description: \n",
      "   Total fields: 3\n",
      "   Sample fields:\n",
      "     - ID_Number (iprs)\n",
      "     - Profile (select)\n",
      "     - Reason For Visiting (narrative)\n",
      "\n",
      "14. Events\n",
      "   Description: \n",
      "   Total fields: 2\n",
      "   Sample fields:\n",
      "     - Event Name (text)\n",
      "     - Narrative (narrative)\n",
      "\n",
      "15. Incidents\n",
      "   Description: \n",
      "   Total fields: 4\n",
      "   Sample fields:\n",
      "     - Incident Type (select)\n",
      "     - Injuries (select)\n",
      "     - Number (text)\n",
      "     ... and 1 more fields\n",
      "\n",
      "16. Natural Disasters\n",
      "   Description: \n",
      "   Total fields: 4\n",
      "   Sample fields:\n",
      "     - Disaster Type (select)\n",
      "     - Injuries (select)\n",
      "     - Number (text)\n",
      "     ... and 1 more fields\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Field Schema Manager\n",
    "\"\"\"\n",
    "This class extracts and manages the field schemas from your sub_module table.\n",
    "It understands what fields are available for each occurrence type (Arson, Theft, Death, etc.).\n",
    "\"\"\"\n",
    "\n",
    "class FieldSchemaManager:\n",
    "    \"\"\"Manages field schemas from sub_module table\"\"\"\n",
    "    \n",
    "    def __init__(self, db: SQLDatabase):\n",
    "        self.db = db\n",
    "        self.schemas = {}\n",
    "        self.load_schemas()\n",
    "    \n",
    "    def load_schemas(self):\n",
    "        \"\"\"Load all field schemas from sub_module table\"\"\"\n",
    "        query = \"SELECT id, name, description, fields FROM sub_module\"\n",
    "        result = self.db.run(query)\n",
    "        \n",
    "        # Parse the result\n",
    "        import ast\n",
    "        rows = ast.literal_eval(result)\n",
    "        \n",
    "        for row in rows:\n",
    "            module_id, name, description, fields_json = row\n",
    "            if fields_json:\n",
    "                self.schemas[module_id] = {\n",
    "                    'name': name,\n",
    "                    'description': description,\n",
    "                    'fields': fields_json\n",
    "                }\n",
    "        \n",
    "        print(f\"Loaded schemas for {len(self.schemas)} modules\")\n",
    "    \n",
    "    def get_field_info(self, module_id: int) -> Dict:\n",
    "        \"\"\"Get field information for a specific module\"\"\"\n",
    "        return self.schemas.get(module_id, {})\n",
    "    \n",
    "    def get_all_field_names(self) -> List[str]:\n",
    "        \"\"\"Get all unique field names across all modules\"\"\"\n",
    "        all_fields = set()\n",
    "        for schema in self.schemas.values():\n",
    "            for field in schema.get('fields', []):\n",
    "                all_fields.add(field.get('name', ''))\n",
    "        return list(all_fields)\n",
    "    \n",
    "    def create_field_description(self, module_id: int) -> str:\n",
    "        \"\"\"Create human-readable field descriptions for LLM\"\"\"\n",
    "        schema = self.get_field_info(module_id)\n",
    "        if not schema:\n",
    "            return \"No schema information available\"\n",
    "        \n",
    "        description = f\"Module: {schema['name']} - {schema['description']}\\n\\nFields:\\n\"\n",
    "        \n",
    "        for field in schema.get('fields', []):\n",
    "            field_name = field.get('name', 'Unknown')\n",
    "            field_type = field.get('type', 'text')\n",
    "            required = field.get('required', False)\n",
    "            options = field.get('options', [])\n",
    "            \n",
    "            description += f\"- {field_name} ({field_type})\"\n",
    "            if required:\n",
    "                description += \" [REQUIRED]\"\n",
    "            if options:\n",
    "                description += f\" Options: {', '.join(options[:5])}{'...' if len(options) > 5 else ''}\"\n",
    "            description += \"\\n\"\n",
    "        \n",
    "        return description\n",
    "\n",
    "# Initialize the schema manager\n",
    "schema_manager = FieldSchemaManager(db)\n",
    "print(\"✅ Field Schema Manager initialized!\")\n",
    "\n",
    "# Display available modules and their schemas\n",
    "print(\"\\nAvailable Occurrence Types and Sample Fields:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for module_id, schema in schema_manager.schemas.items():\n",
    "    print(f\"\\n{module_id}. {schema['name']}\")\n",
    "    print(f\"   Description: {schema['description']}\")\n",
    "    print(f\"   Total fields: {len(schema['fields'])}\")\n",
    "    \n",
    "    # Show first few fields as example\n",
    "    print(\"   Sample fields:\")\n",
    "    for field in schema['fields'][:3]:\n",
    "        field_name = field.get('name', 'Unknown')\n",
    "        field_type = field.get('type', 'text')\n",
    "        print(f\"     - {field_name} ({field_type})\")\n",
    "    \n",
    "    if len(schema['fields']) > 3:\n",
    "        print(f\"     ... and {len(schema['fields']) - 3} more fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfdae557-89e6-497f-aea1-9a54dc974eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSONB Query Builder initialized!\n",
      "\n",
      "Testing Query Builder:\n",
      "========================================\n",
      "✅ Successfully retrieved recent occurrences\n",
      "Sample result (truncated): [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 8, 'Motor Vehicle Theft', 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color...\n",
      "\n",
      "Searching for 'stolen' in occurrences:\n",
      "✅ Found occurrences containing 'stolen'\n",
      "Sample result: [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color': 'Black', 'Model': 'XC90...\n",
      "\n",
      "Occurrence Statistics by Module:\n",
      "Statistics: [('Arson', 287, 8, 71), ('Stolen Lost Item', 48, 12, 0), ('Motor Vehicle Theft', 40, 8, 1), ('Death', 32, 6, 7), ('Cyber Crime', 32, 2, 0), ('Assault', 23, 2, 3), ('Robbery', 18, 12, 0), ('Rape', 14, 1, 1), ('Homicide', 7, 2, 1), ('Missing Person', 4, 1, 0), ('Visits', 2, 0, 0), ('GBV', 1, 0, 0)]...\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Smart JSONB Query Builder\n",
    "\"\"\"\n",
    "This class builds intelligent SQL queries that can extract and interpret \n",
    "data from your JSONB formData columns.\n",
    "\"\"\"\n",
    "\n",
    "class JSONBQueryBuilder:\n",
    "    \"\"\"Build intelligent SQL queries for JSONB data\"\"\"\n",
    "    \n",
    "    def __init__(self, db: SQLDatabase, schema_manager: FieldSchemaManager):\n",
    "        self.db = db\n",
    "        self.schema_manager = schema_manager\n",
    "    \n",
    "    def build_occurrence_query(self, limit: int = 10, module_id: Optional[int] = None) -> str:\n",
    "        \"\"\"Build query to get occurrence data with schema information\"\"\"\n",
    "        base_query = \"\"\"\n",
    "        SELECT \n",
    "            smd.id,\n",
    "            smd.ob_number,\n",
    "            smd.\"submissionDate\",\n",
    "            smd.\"sub_moduleId\",\n",
    "            sm.name as module_name,\n",
    "            sm.description as module_description,\n",
    "            smd.\"formData\",\n",
    "            smd.location,\n",
    "            smd.urgency,\n",
    "            smd.narrative,\n",
    "            ip.first_name,\n",
    "            ip.last_name,\n",
    "            ip.id_no\n",
    "        FROM sub_module_data smd\n",
    "        LEFT JOIN sub_module sm ON smd.\"sub_moduleId\" = sm.id\n",
    "        LEFT JOIN \"IPRS_Person\" ip ON smd.\"iprsId\" = ip.id\n",
    "        \"\"\"\n",
    "        \n",
    "        if module_id:\n",
    "            base_query += f\" WHERE smd.\\\"sub_moduleId\\\" = {module_id}\"\n",
    "        \n",
    "        base_query += f\" ORDER BY smd.\\\"submissionDate\\\" DESC LIMIT {limit}\"\n",
    "        \n",
    "        return base_query\n",
    "    \n",
    "    def search_in_jsonb(self, search_term: str, limit: int = 10) -> str:\n",
    "        \"\"\"Build query to search within JSONB formData\"\"\"\n",
    "        return f\"\"\"\n",
    "        SELECT \n",
    "            smd.id,\n",
    "            smd.ob_number,\n",
    "            smd.\"submissionDate\",\n",
    "            sm.name as module_name,\n",
    "            smd.\"formData\",\n",
    "            smd.location,\n",
    "            smd.urgency\n",
    "        FROM sub_module_data smd\n",
    "        LEFT JOIN sub_module sm ON smd.\"sub_moduleId\" = sm.id\n",
    "        WHERE smd.\"formData\"::text ILIKE '%{search_term}%'\n",
    "        OR smd.narrative ILIKE '%{search_term}%'\n",
    "        ORDER BY smd.\"submissionDate\" DESC\n",
    "        LIMIT {limit}\n",
    "        \"\"\"\n",
    "    \n",
    "    def get_statistics_by_module(self) -> str:\n",
    "        \"\"\"Get occurrence statistics by module type\"\"\"\n",
    "        return \"\"\"\n",
    "        SELECT \n",
    "            sm.name as module_name,\n",
    "            COUNT(*) as total_occurrences,\n",
    "            COUNT(CASE WHEN smd.\"submissionDate\" >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as last_30_days,\n",
    "            COUNT(CASE WHEN smd.urgency = 'High' THEN 1 END) as high_urgency\n",
    "        FROM sub_module_data smd\n",
    "        LEFT JOIN sub_module sm ON smd.\"sub_moduleId\" = sm.id\n",
    "        GROUP BY sm.id, sm.name\n",
    "        ORDER BY total_occurrences DESC\n",
    "        \"\"\"\n",
    "    \n",
    "    def execute_query(self, query: str) -> Any:\n",
    "        \"\"\"Execute query and return results\"\"\"\n",
    "        try:\n",
    "            return self.db.run(query)\n",
    "        except Exception as e:\n",
    "            print(f\"Query execution error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize query builder\n",
    "query_builder = JSONBQueryBuilder(db, schema_manager)\n",
    "print(\"✅ JSONB Query Builder initialized!\")\n",
    "\n",
    "# Test the query builder\n",
    "print(\"\\nTesting Query Builder:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get recent occurrences\n",
    "recent_query = query_builder.build_occurrence_query(limit=3)\n",
    "recent_results = query_builder.execute_query(recent_query)\n",
    "\n",
    "if recent_results:\n",
    "    print(\"✅ Successfully retrieved recent occurrences\")\n",
    "    print(f\"Sample result (truncated): {str(recent_results)[:200]}...\")\n",
    "else:\n",
    "    print(\"❌ No results returned\")\n",
    "\n",
    "# Search for specific terms\n",
    "print(\"\\nSearching for 'stolen' in occurrences:\")\n",
    "search_query = query_builder.search_in_jsonb(\"stolen\", limit=2)\n",
    "search_results = query_builder.execute_query(search_query)\n",
    "\n",
    "if search_results:\n",
    "    print(\"✅ Found occurrences containing 'stolen'\")\n",
    "    print(f\"Sample result: {str(search_results)[:200]}...\")\n",
    "else:\n",
    "    print(\"❌ No 'stolen' occurrences found\")\n",
    "\n",
    "# Get statistics\n",
    "print(\"\\nOccurrence Statistics by Module:\")\n",
    "stats_query = query_builder.get_statistics_by_module()\n",
    "stats_results = query_builder.execute_query(stats_query)\n",
    "if stats_results:\n",
    "    print(f\"Statistics: {str(stats_results)[:300]}...\")\n",
    "else:\n",
    "    print(\"❌ No statistics available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6339f7f4-cc2e-4e13-a9a2-038804ba299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Processor and Vector Store (FINAL FIX) initialized!\n",
      "\n",
      "Debug - Sample result type: <class 'str'>\n",
      "Debug - Sample result: [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 8, 'Motor Vehicle Theft', 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color': 'Black', 'Model': 'XC90', 'location': '22, Brookside Dr', 'Body type': 'SUV', 'Car description': ...\n",
      "\n",
      "✅ Successfully parsed 2 occurrences!\n",
      "Sample processed occurrence:\n",
      "==================================================\n",
      "OB Number: OB/69/1611/7/29/2025\n",
      "Date: 2025-07-29 08:10:11.123000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Reporter: Michel Cheboi\n",
      "ID Number: 36445676\n",
      "\n",
      "Occurrence Details:\n",
      "- Pin: Lat: -1.2561485, long: 36.7919722\n",
      "- Make: Volvo\n",
      "- Color: Black\n",
      "- Model: XC90\n",
      "- Location: 22, Brookside Dr\n",
      "- Body Type: SUV\n",
      "- Car Description: New\n",
      "- Registration Number: KGM 333M\n",
      "- Date And Time Of Occurrence: 2025-07-29 10:53\n",
      "- A Brief Narrative Of What Happened: stolen \n",
      "\n",
      "Narrative: \t 22, Brookside Dr\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Data Processor and Vector Store (FINAL FIX)\n",
    "\"\"\"\n",
    "Process occurrence data for LLM consumption and create vector store for semantic search\n",
    "FINAL FIX: Handle database results with datetime objects properly\n",
    "\"\"\"\n",
    "\n",
    "class OccurrenceDataProcessor:\n",
    "    \"\"\"Process occurrence data for LLM consumption\"\"\"\n",
    "    \n",
    "    def __init__(self, schema_manager: FieldSchemaManager):\n",
    "        self.schema_manager = schema_manager\n",
    "    \n",
    "    def format_occurrence_for_llm(self, occurrence_data: Dict) -> str:\n",
    "        \"\"\"Format occurrence data into human-readable text for LLM\"\"\"\n",
    "        formatted = []\n",
    "        \n",
    "        # Basic occurrence info\n",
    "        formatted.append(f\"OB Number: {occurrence_data.get('ob_number', 'N/A')}\")\n",
    "        formatted.append(f\"Date: {occurrence_data.get('submissionDate', 'N/A')}\")\n",
    "        formatted.append(f\"Type: {occurrence_data.get('module_name', 'N/A')}\")\n",
    "        formatted.append(f\"Description: {occurrence_data.get('module_description', 'N/A')}\")\n",
    "        \n",
    "        if occurrence_data.get('location'):\n",
    "            formatted.append(f\"Location: {occurrence_data['location']}\")\n",
    "        \n",
    "        if occurrence_data.get('urgency'):\n",
    "            formatted.append(f\"Urgency: {occurrence_data['urgency']}\")\n",
    "        \n",
    "        # Person information\n",
    "        if occurrence_data.get('first_name'):\n",
    "            name = f\"{occurrence_data.get('first_name', '')} {occurrence_data.get('last_name', '')}\".strip()\n",
    "            formatted.append(f\"Reporter: {name}\")\n",
    "        \n",
    "        if occurrence_data.get('id_no'):\n",
    "            formatted.append(f\"ID Number: {occurrence_data['id_no']}\")\n",
    "        \n",
    "        # Process JSONB form data\n",
    "        form_data = occurrence_data.get('formData', {})\n",
    "        if isinstance(form_data, str):\n",
    "            try:\n",
    "                form_data = json.loads(form_data)\n",
    "            except:\n",
    "                form_data = {}\n",
    "        \n",
    "        if form_data:\n",
    "            formatted.append(\"\\nOccurrence Details:\")\n",
    "            \n",
    "            for key, value in form_data.items():\n",
    "                if value and str(value).strip() and str(value) != 'null':\n",
    "                    # Clean up the key name\n",
    "                    clean_key = key.replace('_', ' ').title()\n",
    "                    formatted.append(f\"- {clean_key}: {value}\")\n",
    "        \n",
    "        if occurrence_data.get('narrative'):\n",
    "            formatted.append(f\"\\nNarrative: {occurrence_data['narrative']}\")\n",
    "        \n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def create_occurrence_documents(self, occurrences: List[Dict]) -> List[Document]:\n",
    "        \"\"\"Create LangChain documents from occurrence data\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for occurrence in occurrences:\n",
    "            content = self.format_occurrence_for_llm(occurrence)\n",
    "            \n",
    "            metadata = {\n",
    "                'ob_number': occurrence.get('ob_number', ''),\n",
    "                'module_name': occurrence.get('module_name', ''),\n",
    "                'submission_date': str(occurrence.get('submissionDate', '')),\n",
    "                'urgency': occurrence.get('urgency', ''),\n",
    "                'location': occurrence.get('location', '')\n",
    "            }\n",
    "            \n",
    "            documents.append(Document(\n",
    "                page_content=content,\n",
    "                metadata=metadata\n",
    "            ))\n",
    "        \n",
    "        return documents\n",
    "\n",
    "def parse_db_result_to_dict(db_result) -> List[Dict]:\n",
    "    \"\"\"Parse database result into list of dictionaries - FINAL VERSION\"\"\"\n",
    "    try:\n",
    "        # The LangChain SQLDatabase.run() method returns a string representation\n",
    "        # We need to use eval() in a safe way or parse it manually\n",
    "        \n",
    "        if isinstance(db_result, str):\n",
    "            # The string contains datetime objects which ast.literal_eval can't handle\n",
    "            # Let's use a different approach - execute the string with datetime imported\n",
    "            import datetime\n",
    "            \n",
    "            # Create a safe environment for eval\n",
    "            safe_dict = {\n",
    "                \"datetime\": datetime,\n",
    "                \"__builtins__\": {}\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                rows = eval(db_result, safe_dict)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not eval result: {e}\")\n",
    "                # Fallback: try to extract data manually from string\n",
    "                return parse_string_manually(db_result)\n",
    "                \n",
    "        elif isinstance(db_result, (list, tuple)):\n",
    "            rows = db_result\n",
    "        else:\n",
    "            print(f\"Unexpected result type: {type(db_result)}\")\n",
    "            return []\n",
    "        \n",
    "        # Convert to list if it's a single tuple\n",
    "        if isinstance(rows, tuple) and len(rows) > 0 and not isinstance(rows[0], (tuple, list)):\n",
    "            rows = [rows]\n",
    "        \n",
    "        # Define column names based on our query\n",
    "        columns = ['id', 'ob_number', 'submissionDate', 'sub_moduleId', 'module_name', \n",
    "                  'module_description', 'formData', 'location', 'urgency', 'narrative',\n",
    "                  'first_name', 'last_name', 'id_no']\n",
    "        \n",
    "        result = []\n",
    "        for row in rows:\n",
    "            if len(row) >= len(columns):\n",
    "                occurrence_dict = dict(zip(columns, row))\n",
    "                result.append(occurrence_dict)\n",
    "            else:\n",
    "                print(f\"Row has {len(row)} columns, expected {len(columns)}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing result: {e}\")\n",
    "        print(f\"Result type: {type(db_result)}\")\n",
    "        return []\n",
    "\n",
    "def parse_string_manually(db_result_string: str) -> List[Dict]:\n",
    "    \"\"\"Fallback manual parsing if eval fails\"\"\"\n",
    "    try:\n",
    "        # This is a simple fallback - in practice, you might want more robust parsing\n",
    "        print(\"Attempting manual string parsing...\")\n",
    "        \n",
    "        # For now, let's try a simple approach\n",
    "        # Extract the tuples from the string manually\n",
    "        import re\n",
    "        \n",
    "        # Find all tuples in the string\n",
    "        tuple_pattern = r'\\(([^)]+)\\)'\n",
    "        matches = re.findall(tuple_pattern, db_result_string)\n",
    "        \n",
    "        print(f\"Found {len(matches)} potential matches\")\n",
    "        return []  # Return empty for now, but at least we won't crash\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Manual parsing failed: {e}\")\n",
    "        return []\n",
    "\n",
    "class OccurrenceVectorStore:\n",
    "    \"\"\"Manage vector store for occurrence data\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings, data_processor: OccurrenceDataProcessor, query_builder: JSONBQueryBuilder):\n",
    "        self.embeddings = embeddings\n",
    "        self.data_processor = data_processor\n",
    "        self.query_builder = query_builder\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "    \n",
    "    def load_occurrences_to_vectorstore(self, limit: int = 50):\n",
    "        \"\"\"Load occurrences into vector store\"\"\"\n",
    "        print(f\"Loading {limit} recent occurrences into vector store...\")\n",
    "        \n",
    "        # Get occurrence data\n",
    "        query = self.query_builder.build_occurrence_query(limit=limit)\n",
    "        results = self.query_builder.execute_query(query)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No occurrence data found\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Raw result type: {type(results)}\")\n",
    "        print(f\"Raw result sample: {str(results)[:200]}...\")\n",
    "        \n",
    "        # Parse results\n",
    "        occurrences = parse_db_result_to_dict(results)\n",
    "        print(f\"Parsed {len(occurrences)} occurrences\")\n",
    "        \n",
    "        if not occurrences:\n",
    "            print(\"❌ No occurrences parsed successfully\")\n",
    "            return\n",
    "        \n",
    "        # Create documents\n",
    "        documents = self.data_processor.create_occurrence_documents(occurrences)\n",
    "        print(f\"Created {len(documents)} documents\")\n",
    "        \n",
    "        # Split documents if they're too long\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        \n",
    "        split_docs = text_splitter.split_documents(documents)\n",
    "        print(f\"Split into {len(split_docs)} chunks\")\n",
    "        \n",
    "        # Create vector store\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=split_docs,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=\"./occurrence_vectorstore\"\n",
    "        )\n",
    "        \n",
    "        # Create retriever\n",
    "        self.retriever = self.vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 5}\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Vector store created successfully!\")\n",
    "    \n",
    "    def search_similar_occurrences(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"Search for similar occurrences\"\"\"\n",
    "        if not self.retriever:\n",
    "            print(\"Vector store not initialized. Call load_occurrences_to_vectorstore first.\")\n",
    "            return []\n",
    "        \n",
    "        return self.retriever.invoke(query)\n",
    "\n",
    "# Re-initialize data processor and vector store\n",
    "data_processor = OccurrenceDataProcessor(schema_manager)\n",
    "vector_store = OccurrenceVectorStore(embeddings, data_processor, query_builder)\n",
    "\n",
    "print(\"✅ Data Processor and Vector Store (FINAL FIX) initialized!\")\n",
    "\n",
    "# Test data processing with sample occurrences\n",
    "sample_query = query_builder.build_occurrence_query(limit=2)\n",
    "sample_results = query_builder.execute_query(sample_query)\n",
    "\n",
    "print(f\"\\nDebug - Sample result type: {type(sample_results)}\")\n",
    "print(f\"Debug - Sample result: {str(sample_results)[:300]}...\")\n",
    "\n",
    "if sample_results:\n",
    "    sample_occurrences = parse_db_result_to_dict(sample_results)\n",
    "    \n",
    "    if sample_occurrences:\n",
    "        print(f\"\\n✅ Successfully parsed {len(sample_occurrences)} occurrences!\")\n",
    "        print(\"Sample processed occurrence:\")\n",
    "        print(\"=\" * 50)\n",
    "        formatted_sample = data_processor.format_occurrence_for_llm(sample_occurrences[0])\n",
    "        print(formatted_sample[:500] + \"...\" if len(formatted_sample) > 500 else formatted_sample)\n",
    "    else:\n",
    "        print(\"❌ No sample data to process\")\n",
    "else:\n",
    "    print(\"❌ No sample data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e15dd01-d16e-4940-a956-41d0a3c97f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading occurrences into vector store...\n",
      "Loading 100 recent occurrences into vector store...\n",
      "Raw result type: <class 'str'>\n",
      "Raw result sample: [(1611, 'OB/69/1611/7/29/2025', datetime.datetime(2025, 7, 29, 8, 10, 11, 123000), 8, 'Motor Vehicle Theft', 'Motor Vehicle Theft', {'pin': 'Lat: -1.2561485, long: 36.7919722', 'Make': 'Volvo', 'Color...\n",
      "Parsed 100 occurrences\n",
      "Created 100 documents\n",
      "Split into 102 chunks\n",
      "✅ Vector store created successfully!\n",
      "\n",
      "Testing Semantic Search:\n",
      "==================================================\n",
      "\n",
      "Searching for: 'vehicle theft at sarit center'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1598/7/29/2025\n",
      "Type: Motor Vehicle Theft\n",
      "Content: OB Number: OB/69/1598/7/29/2025\n",
      "Date: 2025-07-28 22:43:38.570000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Reporter: David Mutavi\n",
      "ID ...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/69/1598/7/29/2025\n",
      "Type: Motor Vehicle Theft\n",
      "Content: OB Number: OB/69/1598/7/29/2025\n",
      "Date: 2025-07-28 22:43:38.570000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Reporter: David Mutavi\n",
      "ID ...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/69/1602/7/29/2025\n",
      "Type: Robbery\n",
      "Content: OB Number: OB/69/1602/7/29/2025\n",
      "Date: 2025-07-29 06:18:00.703000\n",
      "Type: Robbery\n",
      "Description: Robbery\n",
      "Reporter: Michael Kamau\n",
      "ID Number: 21393375\n",
      "\n",
      "Occur...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/69/1602/7/29/2025\n",
      "Type: Robbery\n",
      "Content: OB Number: OB/69/1602/7/29/2025\n",
      "Date: 2025-07-29 06:18:00.703000\n",
      "Type: Robbery\n",
      "Description: Robbery\n",
      "Reporter: Michael Kamau\n",
      "ID Number: 21393375\n",
      "\n",
      "Occur...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/012/1584/7/28/2025\n",
      "Type: Motor Vehicle Theft\n",
      "Content: OB Number: OB/012/1584/7/28/2025\n",
      "Date: 2025-07-28 13:31:27.665000\n",
      "Type: Motor Vehicle Theft\n",
      "Description: Motor Vehicle Theft\n",
      "Urgency: Medium\n",
      "Reporter:...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'death due to accident'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/012/1558/7/17/2025\n",
      "Type: Death\n",
      "Content: OB Number: OB/012/1558/7/17/2025\n",
      "Date: 2025-07-17 10:58:58.171000\n",
      "Type: Death\n",
      "Description: Death\n",
      "Urgency: High\n",
      "Reporter: Michel Cheboi\n",
      "ID Number: 3644...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: Occurrence Details:\n",
      "- Pin: Lat: -1.2526035, long: 36.782478\n",
      "- Plot No: 456793P\n",
      "- Location: 47, Shanzu Rd\n",
      "- Type Of Property: Residential\n",
      "- Are You The...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/69/1574/7/18/2025\n",
      "Type: Homicide\n",
      "Content: OB Number: OB/69/1574/7/18/2025\n",
      "Date: 2025-07-18 08:48:58.994000\n",
      "Type: Homicide\n",
      "Description: Intentional murder manslaughter or killing of a person\n",
      "Re...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/012/1581/7/28/2025\n",
      "Type: Death\n",
      "Content: OB Number: OB/012/1581/7/28/2025\n",
      "Date: 2025-07-28 13:29:41.369000\n",
      "Type: Death\n",
      "Description: Death\n",
      "Urgency: Low\n",
      "Reporter: Michel Cheboi\n",
      "ID Number: 36445...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'stolen laptop'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1610/7/29/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/69/1610/7/29/2025\n",
      "Date: 2025-07-29 08:01:56.170000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Michel Cheboi\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/69/1610/7/29/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/69/1610/7/29/2025\n",
      "Date: 2025-07-29 08:01:56.170000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Michel Cheboi\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/1/1578/7/28/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1578/7/28/2025\n",
      "Date: 2025-07-27 22:19:37.064000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/1/1577/7/27/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1577/7/27/2025\n",
      "Date: 2025-07-27 20:36:33.841000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/012/1608/7/29/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/012/1608/7/29/2025\n",
      "Date: 2025-07-29 07:52:49.206000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Urgency: Low\n",
      "Reporter: Michel C...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'fire incidents'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/177/1555/7/3/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/177/1555/7/3/2025\n",
      "Date: 2025-07-03 11:12:36.338000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Urgency: High\n",
      "Report...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: Occurrence Details:\n",
      "- Pin: Lat: -1.2526035, long: 36.782478\n",
      "- Plot No: 456793P\n",
      "- Location: 47, Shanzu Rd\n",
      "- Type Of Property: Residential\n",
      "- Are You The...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/69/1573/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1573/7/18/2025\n",
      "Date: 2025-07-18 08:37:53.022000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Michel Che...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/012/1586/7/28/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/012/1586/7/28/2025\n",
      "Date: 2025-07-28 13:32:02.977000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Urgency: High\n",
      "Repor...\n",
      "-------------------------\n",
      "\n",
      "Searching for: 'missing person child'\n",
      "------------------------------\n",
      "\n",
      "Result 1:\n",
      "OB Number: OB/1/1578/7/28/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1578/7/28/2025\n",
      "Date: 2025-07-27 22:19:37.064000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "Result 2:\n",
      "OB Number: OB/69/1575/7/18/2025\n",
      "Type: Arson\n",
      "Content: OB Number: OB/69/1575/7/18/2025\n",
      "Date: 2025-07-18 11:42:32.809000\n",
      "Type: Arson\n",
      "Description: Vandalizing or damaging by burning down\n",
      "Reporter: Faith Amus...\n",
      "-------------------------\n",
      "\n",
      "Result 3:\n",
      "OB Number: OB/233/1592/7/28/2025\n",
      "Type: Missing Person\n",
      "Content: OB Number: OB/233/1592/7/28/2025\n",
      "Date: 2025-07-28 13:33:51.910000\n",
      "Type: Missing Person\n",
      "Description: Missing Person\n",
      "Urgency: Medium\n",
      "Reporter: Mutuku Ky...\n",
      "-------------------------\n",
      "\n",
      "Result 4:\n",
      "OB Number: OB/233/1592/7/28/2025\n",
      "Type: Missing Person\n",
      "Content: OB Number: OB/233/1592/7/28/2025\n",
      "Date: 2025-07-28 13:33:51.910000\n",
      "Type: Missing Person\n",
      "Description: Missing Person\n",
      "Urgency: Medium\n",
      "Reporter: Mutuku Ky...\n",
      "-------------------------\n",
      "\n",
      "Result 5:\n",
      "OB Number: OB/1/1577/7/27/2025\n",
      "Type: Stolen Lost Item\n",
      "Content: OB Number: OB/1/1577/7/27/2025\n",
      "Date: 2025-07-27 20:36:33.841000\n",
      "Type: Stolen Lost Item\n",
      "Description: Stolen Lost Item\n",
      "Reporter: Faith Amusibwa\n",
      "ID Numbe...\n",
      "-------------------------\n",
      "\n",
      "✅ Vector store loaded and semantic search tested!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load Vector Store and Test Semantic Search\n",
    "\"\"\"\n",
    "Load occurrence data into vector store and test semantic search capabilities\n",
    "\"\"\"\n",
    "\n",
    "# Load occurrences into vector store (this may take a few moments)\n",
    "print(\"Loading occurrences into vector store...\")\n",
    "vector_store.load_occurrences_to_vectorstore(limit=100)  # Start with 30 for testing\n",
    "\n",
    "# Test semantic search capabilities\n",
    "test_queries = [\n",
    "    \"vehicle theft at sarit center\",\n",
    "    \"death due to accident\", \n",
    "    \"stolen laptop\",\n",
    "    \"fire incidents\",\n",
    "    \"missing person child\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting Semantic Search:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nSearching for: '{query}'\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    results = vector_store.search_similar_occurrences(query, k=2)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i}:\")\n",
    "        print(f\"OB Number: {doc.metadata.get('ob_number', 'N/A')}\")\n",
    "        print(f\"Type: {doc.metadata.get('module_name', 'N/A')}\")\n",
    "        print(f\"Content: {doc.page_content[:150]}...\")\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "print(\"\\n✅ Vector store loaded and semantic search tested!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "360f0f1e-f598-4e06-a30d-b8c39d815c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enhanced Occurrence RAG System initialized!\n",
      "\n",
      "Testing Enhanced RAG System\n",
      "============================================================\n",
      "\n",
      "1. Question: What types of vehicle theft have been reported recently?\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence reports, the following types of vehicle theft have been reported recently:\n",
      "\n",
      "*   **Motor Vehicle Theft:** Several instances of Motor Vehicle Theft have been reported. Examples include:\n",
      "\n",
      "    *   OB/69/1611/7/29/2025: A Black Volvo XC90 with registration number KGM 333M...\n",
      "\n",
      "============================================================\n",
      "\n",
      "2. Question: Tell me about arson cases and what property types are affected\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, here's a summary of arson cases:\n",
      "\n",
      "**Arson Cases:**\n",
      "\n",
      "The data contains several occurrences classified as Arson. The description for each is \"Vandalizing or damaging by burning down.\" Available fields for Arson cases include:\n",
      "\n",
      "*   **OB Number:** A unique identifi...\n",
      "\n",
      "============================================================\n",
      "\n",
      "3. Question: What fields are available when reporting a missing person?\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, when reporting a Missing Person, the following fields are available:\n",
      "\n",
      "*   **Age:**\n",
      "*   **Pin:** (Latitude and Longitude)\n",
      "*   **Name:**\n",
      "*   **Gender:**\n",
      "*   **Location:**\n",
      "*   **Height(Feet):**\n",
      "*   **Weight (Kgs):**\n",
      "*   **Attach A Photo:**\n",
      "*   **When Last Seen:**\n",
      "...\n",
      "\n",
      "============================================================\n",
      "\n",
      "4. Question: How many death cases have been reported?\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided data, there are no reported \"Death\" cases.\n",
      "\n",
      "Here's a breakdown of the available occurrence types and their fields, as well as a summary of the provided occurrences:\n",
      "\n",
      "**Available Occurrence Types and Their Fields:**\n",
      "\n",
      "*   **Arson:** Vandalizing or damaging by burning down\n",
      "*   **A...\n",
      "\n",
      "============================================================\n",
      "\n",
      "5. Question: What are the common locations for theft incidents?\n",
      "--------------------------------------------------\n",
      "Answer: Based on the provided occurrence data, the location \"MWXC+MJ\" appears in two Stolen Lost Item reports: OB/1/1578/7/28/2025 and OB/1/1577/7/27/2025. Another Stolen Lost Item incident occurred at \"47, Shanzu Rd\" (Plot No: 456793P)\n",
      "\n",
      "To provide a more comprehensive analysis of common theft locations, a ...\n",
      "\n",
      "============================================================\n",
      "\n",
      "6. Question: How many reporters made occurrence reports this week? List them for me\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Okay, let's analyze the provided occurrence reports to determine how many reporters made reports this week and list their names.\n",
      "\n",
      "Based on the provided data, the relevant dates fall within the week of July 21st to July 27th, 2025.\n",
      "\n",
      "Here's a breakdown of the reporters and their occurrences:\n",
      "\n",
      "*   **Fa...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Enhanced RAG System\n",
    "\"\"\"\n",
    "Create the complete RAG system that understands field schemas and provides intelligent answers\n",
    "\"\"\"\n",
    "\n",
    "class EnhancedOccurrenceRAG:\n",
    "    \"\"\"Enhanced RAG system for occurrence data with schema awareness\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, vector_store: OccurrenceVectorStore, schema_manager: FieldSchemaManager, query_builder: JSONBQueryBuilder):\n",
    "        self.llm = llm\n",
    "        self.vector_store = vector_store\n",
    "        self.schema_manager = schema_manager\n",
    "        self.query_builder = query_builder\n",
    "        self.setup_prompts()\n",
    "    \n",
    "    def setup_prompts(self):\n",
    "        \"\"\"Setup prompts for different types of queries\"\"\"\n",
    "        \n",
    "        # General RAG prompt with schema awareness\n",
    "        self.rag_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent assistant analyzing police occurrence reports. You have access to:\n",
    "1. Occurrence data with structured fields\n",
    "2. Field schemas that define what information is available\n",
    "3. Historical occurrence patterns\n",
    "\n",
    "Available Occurrence Types and Their Fields:\n",
    "{schema_info}\n",
    "\n",
    "Context from similar occurrences:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Instructions:\n",
    "- Provide accurate information based on the occurrence data\n",
    "- Mention specific OB numbers when referencing occurrences\n",
    "- Explain what fields are available for different occurrence types\n",
    "- If asked about trends, analyze patterns in the data\n",
    "- If information is not available, clearly state this\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "    \n",
    "    def get_schema_summary(self) -> str:\n",
    "        \"\"\"Get summary of all available schemas\"\"\"\n",
    "        summary = []\n",
    "        for module_id, schema in self.schema_manager.schemas.items():\n",
    "            summary.append(f\"{schema['name']}: {schema['description']}\")\n",
    "        return \"\\n\".join(summary)\n",
    "    \n",
    "    def answer_question(self, question: str) -> str:\n",
    "        \"\"\"Answer question using RAG approach\"\"\"\n",
    "        # Get relevant documents\n",
    "        relevant_docs = self.vector_store.search_similar_occurrences(question)\n",
    "        \n",
    "        # Format context\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "        \n",
    "        # Get schema info\n",
    "        schema_info = self.get_schema_summary()\n",
    "        \n",
    "        # Generate answer\n",
    "        prompt = self.rag_prompt.format(\n",
    "            schema_info=schema_info,\n",
    "            context=context,\n",
    "            question=question\n",
    "        )\n",
    "        \n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response.content\n",
    "\n",
    "# Initialize enhanced RAG system\n",
    "enhanced_rag = EnhancedOccurrenceRAG(llm, vector_store, schema_manager, query_builder)\n",
    "print(\"✅ Enhanced Occurrence RAG System initialized!\")\n",
    "\n",
    "# Test the Enhanced RAG System\n",
    "test_questions = [\n",
    "    \"What types of vehicle theft have been reported recently?\",\n",
    "    \"Tell me about arson cases and what property types are affected\",\n",
    "    \"What fields are available when reporting a missing person?\",\n",
    "    \"How many death cases have been reported?\",\n",
    "    \"What are the common locations for theft incidents?\",\n",
    "    \"How many reporters made occurrence reports this week? List them for me\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting Enhanced RAG System\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        answer = enhanced_rag.answer_question(question)\n",
    "        print(f\"Answer: {answer[:300]}{'...' if len(answer) > 300 else ''}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e54b3090-2099-4c48-b4a3-dbc889585774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Field Schema Understanding:\n",
      "==================================================\n",
      "\n",
      "Q: What information is collected for Motor Vehicle Theft cases?\n",
      "------------------------------\n",
      "A: The following information is collected for Motor Vehicle Theft cases, as seen in the provided occurrences:\n",
      "\n",
      "*   **OB Number:** A unique identifier for the occurrence (e.g., OB/012/1580/7/28/2025).\n",
      "*   **Date:** The date the report was created (e.g., ...\n",
      "\n",
      "Q: What fields are required when reporting an Arson incident?\n",
      "------------------------------\n",
      "A: Based on the provided occurrence reports and the context of similar occurrences, the following fields are present when reporting an Arson incident:\n",
      "\n",
      "*   **Pin:** Latitude and longitude coordinates of the location.\n",
      "*   **Location:** Address or specifi...\n",
      "\n",
      "Q: Show me the available options for Cyber Crime incidents\n",
      "------------------------------\n",
      "A: Based on the provided occurrence reports, the available options for \"Select Incident\" within the Cyber Crime occurrence type are:\n",
      "\n",
      "*   Computer fraud and forgery (OB/69/1518/6/23/2025, OB/69/1517/6/23/2025, OB/012/1553/7/1/2025, OB/012/1531/6/24/2025...\n",
      "\n",
      "\n",
      "Example Queries:\n",
      "==============================\n",
      "\n",
      "Q: What vehicle thefts happened recently?\n",
      "A: Here's a summary of recent motor vehicle thefts based on the provided data:\n",
      "\n",
      "*   **OB/69/1611/7/29/2025:** A black Volvo XC90, registration number KGM 333M, was stolen from 22, Brookside Dr on 2025-07...\n",
      "\n",
      "Q: Show me death cases from accidents\n",
      "A: Based on the provided data, I found one death case related to an accident:\n",
      "\n",
      "*   **OB Number:** OB/012/1558/7/17/2025\n",
      "    *   **Type:** Death\n",
      "    *   **Description:** Death\n",
      "    *   **Details:** A male ...\n",
      "\n",
      "\n",
      "Direct Schema Exploration:\n",
      "========================================\n",
      "Motor Vehicle Theft Fields:\n",
      "Module: Motor Vehicle Theft - Motor Vehicle Theft\n",
      "\n",
      "Fields:\n",
      "- Body type (select) [REQUIRED] Options: Saloon, Sedan, Sports car, SUV, Minivan...\n",
      "- Registration number (text) [REQUIRED]\n",
      "- Make (select) [REQUIRED] Options: Ford, Honda, Toyota, Volvo, Mazda...\n",
      "- Model (text) [REQUIRED]\n",
      "- Color (text) [REQUIRED]\n",
      "- Car description (text)\n",
      "- Date and time of occurrence (datetime) [REQUIRED]\n",
      "- A brief narrative of what happened (narrative)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "🎉 ENHANCED RAG SYSTEM FOR JSONB OCCURRENCE DATA IS READY!\n",
      "================================================================================\n",
      "\n",
      "✅ What We've Built:\n",
      "\n",
      "1. **Field Schema Manager** - Automatically extracts and understands your dynamic field schemas\n",
      "2. **Smart JSONB Query Builder** - Creates intelligent SQL queries for JSONB data\n",
      "3. **Data Processor** - Formats occurrence data for LLM consumption\n",
      "4. **Vector Store** - Enables semantic search on occurrence content\n",
      "5. **Enhanced RAG System** - Provides intelligent, schema-aware responses\n",
      "\n",
      "🚀 Usage Examples:\n",
      "\n",
      "# Query for specific incidents\n",
      "query_occurrences(\"What vehicle thefts happened at Sarit Center?\")\n",
      "\n",
      "# Ask about field schemas  \n",
      "query_occurrences(\"What information is required for reporting arson?\")\n",
      "\n",
      "# Search for patterns\n",
      "query_occurrences(\"Show me all death cases caused by accidents\")\n",
      "\n",
      "# Get field information directly\n",
      "get_field_info(\"Missing Person\")\n",
      "\n",
      "📈 Performance Optimizations:\n",
      "\n",
      "For production use, consider:\n",
      "- Creating GIN indexes on JSONB columns: CREATE INDEX idx_formdata_gin ON sub_module_data USING GIN (\"formData\");\n",
      "- Implementing caching for frequent queries\n",
      "- Using connection pooling for database connections\n",
      "- Batch processing for large vector store updates\n",
      "\n",
      "Your JSONB occurrence data is now intelligently available to your LLM! 🎉\n",
      "\n",
      "\n",
      "Functions ready for use:\n",
      "- query_occurrences(question)\n",
      "- get_field_info(module_name)\n",
      "- enhanced_rag.answer_question(question)\n",
      "- vector_store.search_similar_occurrences(query)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Final Interface and Usage Examples\n",
    "\"\"\"\n",
    "Create a simple interface for querying your occurrence data and demonstrate usage\n",
    "\"\"\"\n",
    "\n",
    "def query_occurrences(question: str):\n",
    "    \"\"\"\n",
    "    Simple function to query your occurrence data\n",
    "    \n",
    "    Examples:\n",
    "    - query_occurrences(\"What vehicle thefts happened at Sarit Center?\")\n",
    "    - query_occurrences(\"Show me recent fire incidents\")\n",
    "    - query_occurrences(\"What fields are available for death reports?\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        answer = enhanced_rag.answer_question(question)\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f\"Error processing question: {e}\"\n",
    "\n",
    "def get_field_info(module_name: str):\n",
    "    \"\"\"\n",
    "    Get detailed field information for a specific occurrence type\n",
    "    \n",
    "    Examples:\n",
    "    - get_field_info(\"Motor Vehicle Theft\")\n",
    "    - get_field_info(\"Arson\")\n",
    "    - get_field_info(\"Missing Person\")\n",
    "    \"\"\"\n",
    "    for module_id, schema in schema_manager.schemas.items():\n",
    "        if schema['name'].lower() == module_name.lower():\n",
    "            return schema_manager.create_field_description(module_id)\n",
    "    \n",
    "    return f\"Module '{module_name}' not found. Available modules: {', '.join([s['name'] for s in schema_manager.schemas.values()])}\"\n",
    "\n",
    "# Test field-specific schema queries\n",
    "schema_questions = [\n",
    "    \"What information is collected for Motor Vehicle Theft cases?\",\n",
    "    \"What fields are required when reporting an Arson incident?\", \n",
    "    \"Show me the available options for Cyber Crime incidents\"\n",
    "]\n",
    "\n",
    "print(\"Testing Field Schema Understanding:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for question in schema_questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(\"-\" * 30)\n",
    "    answer = query_occurrences(question)\n",
    "    print(f\"A: {answer[:250]}{'...' if len(answer) > 250 else ''}\")\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n\\nExample Queries:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "example_questions = [\n",
    "    \"What vehicle thefts happened recently?\",\n",
    "    \"Show me death cases from accidents\"\n",
    "]\n",
    "\n",
    "for q in example_questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"A: {query_occurrences(q)[:200]}...\")\n",
    "\n",
    "# Direct schema exploration\n",
    "print(\"\\n\\nDirect Schema Exploration:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Show detailed schema for Motor Vehicle Theft (ID 8)\n",
    "motor_vehicle_schema = get_field_info(\"Motor Vehicle Theft\")\n",
    "print(\"Motor Vehicle Theft Fields:\")\n",
    "print(motor_vehicle_schema[:500] + \"...\" if len(motor_vehicle_schema) > 500 else motor_vehicle_schema)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎉 ENHANCED RAG SYSTEM FOR JSONB OCCURRENCE DATA IS READY!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "✅ What We've Built:\n",
    "\n",
    "1. **Field Schema Manager** - Automatically extracts and understands your dynamic field schemas\n",
    "2. **Smart JSONB Query Builder** - Creates intelligent SQL queries for JSONB data\n",
    "3. **Data Processor** - Formats occurrence data for LLM consumption\n",
    "4. **Vector Store** - Enables semantic search on occurrence content\n",
    "5. **Enhanced RAG System** - Provides intelligent, schema-aware responses\n",
    "\n",
    "🚀 Usage Examples:\n",
    "\n",
    "# Query for specific incidents\n",
    "query_occurrences(\"What vehicle thefts happened at Sarit Center?\")\n",
    "\n",
    "# Ask about field schemas  \n",
    "query_occurrences(\"What information is required for reporting arson?\")\n",
    "\n",
    "# Search for patterns\n",
    "query_occurrences(\"Show me all death cases caused by accidents\")\n",
    "\n",
    "# Get field information directly\n",
    "get_field_info(\"Missing Person\")\n",
    "\n",
    "📈 Performance Optimizations:\n",
    "\n",
    "For production use, consider:\n",
    "- Creating GIN indexes on JSONB columns: CREATE INDEX idx_formdata_gin ON sub_module_data USING GIN (\"formData\");\n",
    "- Implementing caching for frequent queries\n",
    "- Using connection pooling for database connections\n",
    "- Batch processing for large vector store updates\n",
    "\n",
    "Your JSONB occurrence data is now intelligently available to your LLM! 🎉\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nFunctions ready for use:\")\n",
    "print(\"- query_occurrences(question)\")\n",
    "print(\"- get_field_info(module_name)\")\n",
    "print(\"- enhanced_rag.answer_question(question)\")\n",
    "print(\"- vector_store.search_similar_occurrences(query)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e59748-374d-47e2-aab8-57b9052b707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hybrid Search System initialized!\n",
      "\n",
      "🧪 Testing Hybrid Search System:\n",
      "============================================================\n",
      "\n",
      "1. Testing: How many vehicle thefts were reported in the last month?\n",
      "──────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "🎯 Classified as: HYBRID\n",
      "💡 Reasoning: Error in classification, using hybrid approach\n",
      "\n",
      "Question: How many vehicle thefts were reported in the last month?\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "🤖 Analysis: Using HYBRID approach\n",
      "💭 Reasoning: Error in classification, using hybrid approach\n",
      "------------------------------------------------------------\n",
      "🚀 Executing hybrid search...\n",
      "🔍 Executing SQL search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised NotFound: 404 models/gemini-2.5-flash-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Hybrid Search System\n",
    "\"\"\"\n",
    "Hybrid search that combines:\n",
    "1. SQL-based queries on relational data (structured queries, analytics, counts)\n",
    "2. Vector-based semantic search on occurrence content (similarity, meaning)\n",
    "3. Intelligent routing to determine which method(s) to use\n",
    "\"\"\"\n",
    "\n",
    "class HybridOccurrenceSearch:\n",
    "    \"\"\"Hybrid search system combining SQL and vector search\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, vector_store: OccurrenceVectorStore, query_builder: JSONBQueryBuilder, schema_manager: FieldSchemaManager):\n",
    "        self.llm = llm\n",
    "        self.vector_store = vector_store\n",
    "        self.query_builder = query_builder\n",
    "        self.schema_manager = schema_manager\n",
    "        self.setup_prompts()\n",
    "    \n",
    "    def setup_prompts(self):\n",
    "        \"\"\"Setup prompts for query classification and SQL generation\"\"\"\n",
    "        \n",
    "        # Query classification prompt\n",
    "        self.classifier_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Analyze this question about police occurrence data and classify the search approach needed.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Available search methods:\n",
    "1. SQL - For counts, statistics, filtering by specific criteria, date ranges, aggregations\n",
    "2. VECTOR - For finding similar content, semantic search, narrative descriptions\n",
    "3. HYBRID - For complex questions needing both approaches\n",
    "\n",
    "Examples:\n",
    "- \"How many vehicle thefts in the last month?\" → SQL\n",
    "- \"Show me cases similar to a stolen laptop at university\" → VECTOR  \n",
    "- \"What are the trends in cyber crime and show me examples\" → HYBRID\n",
    "- \"Find arson cases at schools\" → HYBRID\n",
    "- \"Count death cases by cause\" → SQL\n",
    "- \"Cases involving stolen electronics\" → VECTOR\n",
    "\n",
    "Classification: Choose ONE: SQL, VECTOR, or HYBRID\n",
    "Reasoning: Brief explanation of why this approach is best.\n",
    "\n",
    "Response format:\n",
    "METHOD: [SQL/VECTOR/HYBRID]\n",
    "REASONING: [explanation]\n",
    "\"\"\")\n",
    "        \n",
    "        # SQL generation prompt\n",
    "        self.sql_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Generate a PostgreSQL query for this question about police occurrence data.\n",
    "\n",
    "Database Schema:\n",
    "- sub_module_data: Contains occurrence records with JSONB formData\n",
    "  * Columns: id, ob_number, submissionDate, sub_moduleId, formData (JSONB), location, urgency, narrative, iprsId\n",
    "- sub_module: Contains occurrence type definitions\n",
    "  * Columns: id, name, description, fields (JSONB schema)\n",
    "- IPRS_Person: Contains person information\n",
    "  * Columns: id, id_no, first_name, last_name, gender, nationality, email, phone_number\n",
    "\n",
    "Available JSONB fields in formData (commonly used):\n",
    "{available_fields}\n",
    "\n",
    "Important notes:\n",
    "- Use formData->>'field_name' to extract text values from JSONB\n",
    "- Use formData->'field_name' for JSON values  \n",
    "- Join with sub_module to get occurrence type names\n",
    "- Join with IPRS_Person using iprsId for reporter information\n",
    "- Always include ob_number in results for reference\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Generate a valid PostgreSQL query:\n",
    "\"\"\")\n",
    "        \n",
    "        # Hybrid response prompt\n",
    "        self.hybrid_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are analyzing police occurrence data. Answer the question using both SQL results and similar occurrence examples.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "SQL Results (structured data):\n",
    "{sql_results}\n",
    "\n",
    "Similar Occurrences (semantic matches):\n",
    "{vector_results}\n",
    "\n",
    "Available Occurrence Types:\n",
    "{schema_info}\n",
    "\n",
    "Instructions:\n",
    "- Combine insights from both SQL data and similar occurrences\n",
    "- Mention specific OB numbers when referencing cases\n",
    "- Provide quantitative insights from SQL and qualitative examples from vector search\n",
    "- If trends are asked about, analyze patterns in the data\n",
    "- Be comprehensive but concise\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "    \n",
    "    def classify_query(self, question: str) -> tuple:\n",
    "        \"\"\"Classify the query to determine search approach\"\"\"\n",
    "        try:\n",
    "            response = self.llm.invoke(self.classifier_prompt.format(question=question))\n",
    "            content = response.content.strip()\n",
    "            \n",
    "            # Extract method and reasoning\n",
    "            method = \"HYBRID\"  # Default\n",
    "            reasoning = \"Complex question requiring multiple approaches\"\n",
    "            \n",
    "            lines = content.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.startswith('METHOD:'):\n",
    "                    method = line.split(':', 1)[1].strip()\n",
    "                elif line.startswith('REASONING:'):\n",
    "                    reasoning = line.split(':', 1)[1].strip()\n",
    "            \n",
    "            return method, reasoning\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Classification error: {e}\")\n",
    "            return \"HYBRID\", \"Error in classification, using hybrid approach\"\n",
    "    \n",
    "    def generate_sql_query(self, question: str) -> str:\n",
    "        \"\"\"Generate SQL query for the question\"\"\"\n",
    "        available_fields = ', '.join(self.schema_manager.get_all_field_names()[:20])\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(self.sql_prompt.format(\n",
    "                question=question,\n",
    "                available_fields=available_fields\n",
    "            ))\n",
    "            \n",
    "            sql_query = response.content.strip()\n",
    "            \n",
    "            # Clean up SQL (remove markdown formatting)\n",
    "            if sql_query.startswith('```sql'):\n",
    "                sql_query = sql_query[6:]\n",
    "            if sql_query.endswith('```'):\n",
    "                sql_query = sql_query[:-3]\n",
    "            \n",
    "            return sql_query.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"SQL generation error: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def execute_sql_search(self, question: str) -> str:\n",
    "        \"\"\"Execute SQL-based search\"\"\"\n",
    "        print(\"🔍 Executing SQL search...\")\n",
    "        \n",
    "        sql_query = self.generate_sql_query(question)\n",
    "        if not sql_query:\n",
    "            return \"Could not generate SQL query\"\n",
    "        \n",
    "        print(f\"Generated SQL: {sql_query[:100]}...\")\n",
    "        \n",
    "        results = self.query_builder.execute_query(sql_query)\n",
    "        if results:\n",
    "            return f\"SQL Query: {sql_query}\\n\\nResults: {results}\"\n",
    "        else:\n",
    "            return \"No SQL results found\"\n",
    "    \n",
    "    def execute_vector_search(self, question: str) -> str:\n",
    "        \"\"\"Execute vector-based semantic search\"\"\"\n",
    "        print(\"🎯 Executing vector search...\")\n",
    "        \n",
    "        if not self.vector_store.retriever:\n",
    "            return \"Vector store not initialized. Please load occurrences first.\"\n",
    "        \n",
    "        docs = self.vector_store.search_similar_occurrences(question, k=5)\n",
    "        \n",
    "        if docs:\n",
    "            formatted_results = []\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                formatted_results.append(f\"Match {i}:\")\n",
    "                formatted_results.append(f\"OB: {doc.metadata.get('ob_number', 'N/A')}\")\n",
    "                formatted_results.append(f\"Type: {doc.metadata.get('module_name', 'N/A')}\")\n",
    "                formatted_results.append(f\"Content: {doc.page_content[:200]}...\")\n",
    "                formatted_results.append(\"-\" * 40)\n",
    "            \n",
    "            return \"\\n\".join(formatted_results)\n",
    "        else:\n",
    "            return \"No similar occurrences found\"\n",
    "    \n",
    "    def execute_hybrid_search(self, question: str) -> str:\n",
    "        \"\"\"Execute hybrid search combining SQL and vector approaches\"\"\"\n",
    "        print(\"🚀 Executing hybrid search...\")\n",
    "        \n",
    "        # Get SQL results\n",
    "        sql_results = self.execute_sql_search(question)\n",
    "        \n",
    "        # Get vector results  \n",
    "        vector_results = self.execute_vector_search(question)\n",
    "        \n",
    "        # Get schema info\n",
    "        schema_info = \"\\n\".join([f\"{s['name']}: {s['description']}\" for s in self.schema_manager.schemas.values()])\n",
    "        \n",
    "        # Generate combined response\n",
    "        try:\n",
    "            response = self.llm.invoke(self.hybrid_prompt.format(\n",
    "                question=question,\n",
    "                sql_results=sql_results,\n",
    "                vector_results=vector_results,\n",
    "                schema_info=schema_info\n",
    "            ))\n",
    "            \n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generating hybrid response: {e}\\n\\nSQL Results:\\n{sql_results}\\n\\nVector Results:\\n{vector_results}\"\n",
    "    \n",
    "    def search(self, question: str) -> str:\n",
    "        \"\"\"Main search function that automatically chooses the best approach\"\"\"\n",
    "        print(f\"Question: {question}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Classify the query\n",
    "        method, reasoning = self.classify_query(question)\n",
    "        print(f\"🤖 Analysis: Using {method} approach\")\n",
    "        print(f\"💭 Reasoning: {reasoning}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Execute appropriate search\n",
    "        if method == \"SQL\":\n",
    "            return self.execute_sql_search(question)\n",
    "        elif method == \"VECTOR\":\n",
    "            return self.execute_vector_search(question)\n",
    "        else:  # HYBRID\n",
    "            return self.execute_hybrid_search(question)\n",
    "\n",
    "def quick_search(question: str) -> str:\n",
    "    \"\"\"Quick search function for easy use\"\"\"\n",
    "    return hybrid_search.search(question)\n",
    "\n",
    "# Initialize hybrid search system\n",
    "hybrid_search = HybridOccurrenceSearch(llm, vector_store, query_builder, schema_manager)\n",
    "print(\"✅ Hybrid Search System initialized!\")\n",
    "\n",
    "# Test the hybrid search with different types of questions\n",
    "test_questions = [\n",
    "    \"How many vehicle thefts were reported in the last month?\",  # Should use SQL\n",
    "    \"Show me cases similar to stolen electronics at universities\",  # Should use VECTOR\n",
    "    \"What are the trends in cyber crime and give me some examples\",  # Should use HYBRID\n",
    "    \"Find all arson cases affecting schools\",  # Should use HYBRID\n",
    "    \"Count total occurrences by module type\"  # Should use SQL\n",
    "]\n",
    "\n",
    "print(\"\\n🧪 Testing Hybrid Search System:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. Testing: {question}\")\n",
    "    print(\"─\" * 50)\n",
    "    \n",
    "    try:\n",
    "        method, reasoning = hybrid_search.classify_query(question)\n",
    "        print(f\"🎯 Classified as: {method}\")\n",
    "        print(f\"💡 Reasoning: {reasoning}\")\n",
    "        print()\n",
    "        \n",
    "        # For demo, just show classification - uncomment below to run full search\n",
    "        result = hybrid_search.search(question)\n",
    "        print(result[:300] + \"...\" if len(result) > 300 else result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "🎉 Hybrid Search System Ready!\n",
    "\n",
    "Usage Examples:\n",
    "==============\n",
    "\n",
    "# Simple search (automatically chooses best method)\n",
    "quick_search(\"How many death cases in the last week?\")\n",
    "\n",
    "# Detailed search with method explanation  \n",
    "hybrid_search.search(\"Find cases similar to laptop theft at university\")\n",
    "\n",
    "# The system will automatically:\n",
    "# 1. Analyze your question\n",
    "# 2. Choose SQL, VECTOR, or HYBRID approach\n",
    "# 3. Execute the appropriate search\n",
    "# 4. Return comprehensive results\n",
    "\n",
    "Try asking questions like:\n",
    "- \"How many motor vehicle thefts in July 2025?\"\n",
    "- \"Show me cases similar to fire incidents at schools\"  \n",
    "- \"What are the patterns in cyber crime and show examples\"\n",
    "- \"Find all high urgency cases involving stolen electronics\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69d77e-35c2-4d2d-8299-bfd7ecc755fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
